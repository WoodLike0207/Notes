# Redis



## 1.  Redisson 分布式锁的实现原理

Redisson 是一个基于 Redis 的 Java 驻内存数据网格（In-Memory Data Grid）。它提供的分布式锁是其最著名的功能之一，相比于自己基于 `SETNX` 等命令实现的简易分布式锁，Redisson 的锁功能更加健壮和完善。

其核心实现原理可以概括为以下几点：

1. **基于 Hash 数据结构存锁信息**
2. **利用 Lua 脚本保证操作原子性**
3. **巧妙的 Watchdog（看门狗）机制实现锁的自动续期**
4. **支持可重入锁和公平锁等高级特性**

下面我们来详细解析这几个核心环节。



### 1. 加锁 (Lock) 的实现

当你调用 `RLock lock = redisson.getLock("myLock"); lock.lock();` 时，Redisson 内部会执行一段精心设计的 Lua 脚本。

与很多人想象的不同，Redisson 并非简单地使用 `SETNX` 命令。它采用的是 Redis 的 **Hash** 数据结构。一个锁在 Redis 中会以一个 Hash 键的形式存在，例如键名为 `myLock`。

这个 Hash 结构中主要包含两个字段：

- **锁的持有者标识**：一个唯一的ID，通常是 `UUID:threadId`，用来标识哪个客户端的哪个线程持有了这个锁。
- **重入次数 (reentrancy count)**：一个计数器，用于实现可重入锁的逻辑。

**加锁的 Lua 脚本逻辑大致如下 (伪代码):**

Lua

```lua
-- KEYS[1] 是锁的 Key，例如 "myLock"
-- ARGV[1] 是锁的过期时间（毫秒）
-- ARGV[2] 是锁的持有者标识，例如 "uuid:threadId"

-- 1. 判断锁是否存在
if (redis.call('exists', KEYS[1]) == 0) then
    -- 1.1. 锁不存在，直接获取锁
    redis.call('hset', KEYS[1], ARGV[2], 1); -- 设置持有者和重入次数为1
    redis.call('pexpire', KEYS[1], ARGV[1]); -- 设置过期时间
    return nil; -- 返回 nil 表示加锁成功
end;

-- 2. 判断锁是否被当前线程持有
if (redis.call('hexists', KEYS[1], ARGV[2]) == 1) then
    -- 2.1. 锁已存在，且是当前线程持有，实现可重入
    redis.call('hincrby', KEYS[1], ARGV[2], 1); -- 重入次数+1
    redis.call('pexpire', KEYS[1], ARGV[1]); -- 重新设置过期时间
    return nil; -- 返回 nil 表示加锁成功
end;

-- 3. 锁已存在，且被其他线程持有，加锁失败
return redis.call('pttl', KEYS[1]); -- 返回锁的剩余过期时间
```

为什么使用 Lua 脚本？

因为 Redis 执行 Lua 脚本是原子性的。上述“判断-操作-设置过期”等一系列操作会被当作一个不可分割的整体来执行，杜绝了并发场景下可能出现的竞态条件。如果单纯用多个命令组合，在分布式环境下，执行到一半时可能会出现问题。



### 2. Watchdog（看门狗）自动续期机制



这是 Redisson 分布式锁最核心、最巧妙的设计，它解决了“业务执行时间超过锁的过期时间而被动释放锁”的致命问题。

**工作原理：**

1. **加锁成功后启动**：当一个线程成功获取到锁之后，如果用户没有显式指定锁的过期时间（即调用 `lock()` 而不是 `lock(leaseTime, unit)`），Redisson 会默认设置一个30秒的过期时间，并**在后台启动一个定时任务**，这就是“看门狗”。
2. **定时检查与续期**：这个看门狗是一个后台线程，它会**每隔10秒**（默认是 `lockWatchdogTimeout / 3`）检查一下持有锁的客户端线程是否还存在。如果线程还存在（意味着业务逻辑还没执行完），看门狗就会**重新将锁的过期时间设置为30秒**。
3. **业务完成时停止**：当持有锁的线程执行完业务逻辑，调用 `unlock()` 方法释放锁时，会取消这个后台的定时任务。
4. **宕机情况**：如果持有锁的客户端不幸宕机，它无法正常释放锁。但由于看门狗线程也随之消失，不会再为这个锁续期。因此，这个锁会在最多30秒后自动过期，从而避免了死锁的产生。

**总结：** 看门狗机制通过在后台不断“续命”的方式，保证了只要业务逻辑没有执行完毕，锁就不会因为超时而释放，极大地提高了分布式锁的可靠性。



### 3. 解锁 (Unlock) 的实现



解锁操作同样是通过一段 Lua 脚本来保证原子性。

**解锁的 Lua 脚本逻辑大致如下 (伪代码):**

Lua

```lua
-- KEYS[1] 是锁的 Key
-- ARGV[1] 是 unlock 消息（用于发布/订阅，后面解释）
-- ARGV[2] 是锁的持有者标识 "uuid:threadId"

-- 1. 判断锁是否存在，以及是否由当前线程持有
if (redis.call('hexists', KEYS[1], ARGV[2]) == 0) then
    return nil; -- 锁不存在或不是自己持有的，直接返回
end;

-- 2. 是自己持有的锁，将重入次数-1
local counter = redis.call('hincrby', KEYS[1], ARGV[2], -1);

-- 3. 判断重入次数是否已降为0
if (counter > 0) then
    -- 3.1. 计数器还大于0，说明还在重入状态，不能删锁，只更新过期时间
    redis.call('pexpire', KEYS[1], ARGV[3]); -- ARGV[3] 是新的过期时间
    return 0;
else
    -- 3.2. 计数器为0，可以安全删除锁
    redis.call('del', KEYS[1]);
    -- 并且发布一个 "unlock" 消息，通知其他等待的线程可以尝试获取锁了
    redis.call('publish', KEYS[1] .. ':unlock_message', ARGV[1]);
    return 1;
end;
```



### 4. 阻塞与唤醒机制 (可中断锁)



当一个线程尝试加锁失败时（`lock.lock()`），它如何“阻塞”等待呢？

Redisson 利用了 Redis 的 **Pub/Sub (发布/订阅)** 机制。

1. **订阅**：尝试加锁失败的线程，会订阅一个与锁的 Key 相关的特定 channel（例如 `redisson_lock__channel__{myLock}`）。
2. **等待**：订阅后，线程会进入一个循环，不断地尝试获取锁，并在失败后通过一个 `Semaphore` 或 `CountDownLatch` 陷入等待状态，等待被唤醒或超时。
3. **发布（唤醒）**：当持有锁的客户端调用 `unlock()` 方法时，除了会删除锁的 Key，还会向上述 channel **发布一条 "unlock" 消息**。
4. **接收与尝试**：所有订阅了该 channel 的等待线程都会收到这条消息，然后被唤醒，从等待状态中出来，重新开始新一轮的尝试加锁。

这种基于发布订阅的机制，避免了像 `while(true)` 循环不断请求 Redis 的 “忙等” 模式，减少了对 Redis 服务器的无用压力，更加高效。



### 总结

Redisson 分布式锁的实现原理是一个精巧的组合：

- **数据层面**：使用 Hash 结构存储锁信息，支持了**可重入**特性。
- **原子性保障**：核心的加锁和解锁逻辑都封装在 **Lua 脚本**中，由 Redis 服务端原子性执行，杜绝了并发问题。
- **高可用性**：通过**看门狗（Watchdog）机制**，实现了锁的自动续期，有效防止了因业务执行时间过长导致的锁失效问题，避免了把别人的锁误删的风险。
- **高性能等待**：利用 Redis 的**发布/订阅机制**实现了异步的、低功耗的等待/唤醒逻辑，避免了客户端的空转和对 Redis 的无效轮询。

正是这些设计的结合，使得 Redisson 的分布式锁成为目前业界公认的、功能最完善、最可靠的实现之一。



## 2. 主从同步原理

这确实是 Redis 复制机制中最容易混淆，但也是含金量最高的细节。面试官问这两个 Buffer，通常是为了考察你对**“全量同步 vs 增量同步”**以及**“OOM（内存溢出）风险”**的深度理解。

我们把 Redis 主从同步的整个过程拆解开，把这两个 Buffer 放到具体的场景里去讲，你一下子就明白了。

------

### 同步的三种状态

Redis 的主从同步主要分为三个阶段：

1. **全量复制 (Full Sync)**：第一次握手，或者严重滞后时。
2. **命令传播 (Command Propagate)**：正常运行时的实时同步。
3. **增量复制 (Partial Sync)**：网络抖动短暂断开后的“补发数据”。

这两个 Buffer 就在这三个阶段中扮演不同的角色。

------

### 1. 角色一：Replication Buffer (复制缓冲区)

**一句话定义**：它是**每个 Slave 独有的**、用于存放“待发送给该 Slave 的命令”的队列。

#### 它的本质

在 Redis 内部，**每一个**连接到 Master 的客户端（无论是普通的 Java 客户端，还是作为客户端的 Slave），Master 都会为其分配一个 **Client Output Buffer（客户端输出缓冲区）**。

- 当这个客户端是 Slave 时，我们习惯称之为 `replication buffer`。
- **注意**：如果有 10 个 Slave，Master 上就会有 **10 个** `replication buffer`。

#### 它在什么时候用？

**场景 A：全量同步期间（最关键）**

1. Master 执行 `BGSAVE` 生成 RDB 文件。
2. **关键点：** 在生成 RDB 和传输 RDB 的这段时间（可能几秒到几分钟），Master 依然在接收前端的写请求。
3. Master 不能把这些新写的命令丢掉，否则 Slave 加载完 RDB 就少数据了。
4. Master 会把这些**新来的写命令**存入该 Slave 对应的 `replication buffer` 中。
5. 等 RDB 传完，Master 再把这个 Buffer 里的命令发给 Slave。

**场景 B：正常命令传播期间**

- Master 接收到一个写命令 `SET k v`。
- Master 把它写入自己的内存，然后把这个命令塞进所有 Slave 的 `replication buffer`。
- 通过网络发送给 Slave。

#### 它的隐患 (OOM & 复制风暴)

如果 `replication buffer` 里的数据积压太多，超过了限制（`client-output-buffer-limit slave`），Master 会强制断开与 Slave 的连接。

- **后果**：Slave 断开后重连，又触发全量同步 -> 再次积压 Buffer -> 再次断开。这就是**“死循环”**。
- **原因**：通常是因为 RDB 太大、网络太慢、或者 Master 写请求太猛。

------

### 2. 角色二：repl_backlog_buffer (复制积压缓冲区)

**一句话定义**：它是**所有 Slave 共享的**、一个**固定大小**的**环形缓冲区 (Ring Buffer)**。

#### 它的本质

- Master 上**只有一个** `repl_backlog_buffer`，无论有多少个 Slave。
- 它默认比较小（比如 1MB，由 `repl-backlog-size` 控制）。
- 它是“先进先出”的，写满了就会覆盖最早的数据（环形覆盖）。

#### 它在什么时候用？—— 增量复制 (Partial Sync)

当 Slave 和 Master 的网络抖动了一下（断开了一小会儿），Slave 重新连上 Master。

Slave 说：“大哥，我之前的 offset 是 1000，我掉线了，能把 1000 以后的数据补给我吗？”

Master 会去检查 `repl_backlog_buffer`：

- **情况 1 (Happy Path)**：Master 发现 `offset` 1000 后的数据还在这个环形缓冲区里（没被新数据覆盖）。
  - **动作**：Master 直接把缓冲区里 1000 之后的数据发给 Slave。
  - **结果**：**增量复制**（速度极快，不需要 RDB）。
- **情况 2 (Sad Path)**：Master 发现数据更新太快，环形缓冲区转了一圈，把 `offset` 1000 的数据已经覆盖掉了（现在的最小 offset 已经是 2000 了）。
  - **动作**：Master 两手一摊：“你来晚了，数据丢了。”
  - **结果**：只能触发**全量复制**（BGSAVE -> RDB）。

------

### 3. 终极对比：两个 Buffer 谁是谁？

这是面试时的**杀手级**总结表格：

| **特性**     | **Replication Buffer**                          | **Repl_backlog_buffer**                          |
| ------------ | ----------------------------------------------- | ------------------------------------------------ |
| **存在数量** | **每个 Slave 一个** (N 个)                      | **Master 全局唯一** (1 个)                       |
| **存在形式** | 链表/队列 (内存可动态增长)                      | **环形缓冲区** (固定大小)                        |
| **主要用途** | 存放发给 Slave 的命令 (全量期间积压 + 实时转发) | 应对网络抖动，实现**增量同步**                   |
| **生命周期** | Slave 连接断开即销毁                            | Master 启动后一直存在                            |
| **内存风险** | **高**。如果积压过多会导致 OOM 或连接断开。     | **低**。固定大小，只会覆盖旧数据，不会撑爆内存。 |
| **决定因素** | 决定了全量同步能否成功                          | 决定了断线重连后能否走“增量复制”                 |

------

### 4. 完整的同步流程（串联起来）

现在我们用这两个概念把整个流程串一遍：

1. **建立连接**：Slave 启动，发送 `PSYNC`。
2. **判定**：
   - 如果是第一次连接 -> **全量复制**。
   - 如果是重连，检查 `repl_backlog_buffer`。如果在范围内 -> **增量复制**；否则 -> **全量复制**。
3. **全量复制阶段**：
   - Master `BGSAVE` 生成 RDB。
   - **关键**：Master 继续接收写请求，写到内存，同时写到 **`repl_backlog_buffer`**，并且写到该 Slave 的 **`replication buffer`**。
   - Master 发送 RDB 给 Slave。
   - Master 发送 **`replication buffer`** 里的积压命令给 Slave。
4. **命令传播阶段** (正常运行)：
   - Master 接收写命令 `SET a 1`。
   - Master 把 `SET a 1` 写到 **`repl_backlog_buffer`** (为了防备未来 Slave 断连)。
   - Master 把 `SET a 1` 写到所有 Slave 的 **`replication buffer`**，通过网络发出去。

------

### 5. 假如你是架构师（面试实战）

面试官可能会问：**“由于网络不好，我的 Redis 经常触发全量同步，导致性能很差，怎么优化？”**

基于上面的原理，你有两个调优方向：

1. **调大 `repl-backlog-size`**：
   - 原理：增大环形缓冲区的大小。
   - 效果：让积压缓冲区能容纳更长时间的数据。即使网络断开 1 分钟，offset 还没被覆盖，依然可以用增量复制，避免全量复制。
   - *比如：网络偶尔断 60s，你的 QPS 是 1000，每条命令 1KB。那你至少需要 60 \* 1000 \* 1KB = 60MB 的 backlog。*
2. **调大 `client-output-buffer-limit slave`**：
   - 原理：允许 `replication buffer` 积压更多数据。
   - 效果：防止在全量复制传输 RDB 期间，因为积压命令过多导致 Master 主动断开 Slave，从而避免陷入“全量复制 -> 失败 -> 重试”的死循环。



## 3. Redis集群原理

这绝对是 Redis 进阶面试中的**终极 Boss**。

我们之前讲的哨兵（Sentinel），解决了“高可用”问题（Master 挂了有人顶上）。

但哨兵架构有一个致命的天花板：它依然是单机写入。

无论你有多少个 Slave，写请求只能打到 Master 一个节点上。如果你的业务要做类似于“双十一”的秒杀，或者 Bilibili 那样海量的弹幕写入，单机内存（比如 64GB）和单机 CPU 很快就会成为瓶颈。

**Redis Cluster（集群）** 就是为了打破这个天花板而生的。它实现了 **分布式存储（Sharding/分片）**，让多台机器同时承担写入和存储。

我们把它拆解为 **3 个核心原理** 来讲。

------

### 1. 核心数据分布：哈希槽 (Hash Slot)

这是面试官最喜欢问的：“Redis Cluster 是怎么分片的？是一致性哈希吗？”

答：不是一致性哈希，而是哈希槽。

Redis Cluster 将整个数据库划分为 **16384** 个小格子，这些格子就叫 **哈希槽 (Hash Slot)**。

#### 分布算法

当你存一个 Key（比如 `SET user:100 "Alice"`）时，Redis 不会随便找个节点存，而是按以下公式计算：

$$Slot = CRC16(key) \pmod{16384}$$

1. 对 Key 进行 CRC16 算法计算。
2. 对 16384 取模，得到一个 0 ~ 16383 之间的数字。
3. 这个数字对应哪个节点，数据就存到哪个节点。

#### 槽位分配

假设你的集群有 3 个 Master 节点（A, B, C）：

- **节点 A** 负责：0 ~ 5460 号槽。
- **节点 B** 负责：5461 ~ 10922 号槽。
- **节点 C** 负责：10923 ~ 16383 号槽。

> 面试坑题：为什么是 16384 个槽？
>
> (这是一个加分项)
>
> 作者 Antirez 解释过：在 Redis 节点间通信（Gossip 协议）时，需要携带自己负责的槽位信息（Bitmap）。
>
> - 16384 个槽 = 16k 位 = 2KB 数据。这是心跳包大小和网络带宽的平衡点。
> - 如果用 65536 (CRC16 的最大值)，心跳包会变大到 8KB，在频繁通信时太占带宽。
> - 而且 Redis Cluster 官方建议节点数不超过 1000 个，16384 对于 1000 个节点来说足够均匀了。

------

### 2. 核心交互：去中心化 & 重定向 (MOVED / ASK)

Redis Cluster 是 无中心架构 (P2P)。也就是说，没有一个类似于 Nginx 的“代理节点”在前面分发请求。

客户端（比如你的 Java 代码）可以直接连接集群中的任意一个节点。

但是，如果我要查 `user:100`，我连接的是节点 A，但 `user:100` 算出来的槽位其实在节点 B 上，怎么办？

这就涉及到了**客户端重定向**机制。

#### 情况一：MOVED 错误 (永久重定向)

1. **客户端**：向 **节点 A** 发送 `GET user:100`。
2. **节点 A**：计算 `CRC16(user:100)`，发现属于 **槽位 5000**。
3. **节点 A**：查表发现槽位 5000 归 **节点 B** 管。
4. **节点 A**：返回一个 `MOVED 5000 192.168.1.2:6379` 的错误给客户端。
5. **客户端**：收到错误，**更新本地的槽位映射表**（以后再查 5000 槽，直接找 B），然后重新向 **节点 B** 发送请求。

#### 情况二：ASK 错误 (临时重定向)

这发生在**集群扩容（Resharding）**的时候。比如你正在把槽位 5000 从节点 A 迁移到节点 B。

1. **客户端**：向 **节点 A** 请求 `user:100`（属于槽位 5000）。
2. **节点 A**：发现槽位 5000 还在自己这，但 `user:100` 这个 Key 已经被迁移到 **节点 B** 了。
3. **节点 A**：返回 `ASK 5000 192.168.1.2:6379`。
4. **客户端**：收到 ASK，知道这是“临时的”。它向 **节点 B** 发送一个 `ASKING` 命令（打个招呼），然后再发送 `GET user:100`。
5. **区别**：客户端**不会**更新本地的槽位映射表。下次查槽位 5000，它还是会先问 A。

> Java 客户端 (Jedis/Lettuce) 的做法：
>
> 这一层逻辑被封装在 SDK 里了。你在代码里写 jedis.get("key") 时，底层如果收到了 MOVED，会自动重连新节点，你的业务代码是无感知的。

------

### 3. 核心通信：Gossip 协议

集群里的节点（比如 A, B, C）是怎么知道“谁挂了”、“哪个槽归谁管”的？

它们通过 Gossip（八卦）协议 互相传播信息。

每个节点都开了一个额外的端口（通常是 业务端口 + 10000，比如 16379），专门用来和其他节点“聊八卦”。

- **PING**：随机挑几个节点发消息：“我是 A，我负责 0-5000，我觉得 C 好像挂了，你们知道吗？”
- **PONG**：接收方回复：“我是 B，我知道了。另外我发现 D 也是好的。”

通过这种病毒式的传播，集群的状态最终会在几秒钟内达到一致。

------

### 4. 高可用与故障转移 (Failover)

Cluster 模式自带了 Sentinel 的功能。每个 Master 节点下面通常会挂 1 个或多个 Slave。

**如果 Master A 挂了：**

1. **PFAIL (疑似下线)**：节点 B 发现连不上 A 了，把 A 标记为 PFAIL。
2. **FAIL (确认下线)**：节点 B 把这个消息通过 Gossip 告诉其他节点。如果集群里**超过半数**的 Master 都认为 A 挂了，A 就会被标记为 FAIL。
3. **选举**：A 的 Slave 们会发起选举（基于 Raft 协议）。
4. **上位**：胜出的 Slave 升级为新的 Master，接管 A 原来的槽位。
5. **广播**：通过 Gossip 告诉大家：“槽位 0-5460 现在归我管了”。

------

### 5. 面试深挖：Cluster 的限制 (关键！)

用 Redis Cluster 不是没有代价的，这几点**非常限制业务开发**，也是面试常考点：

1. **只能使用 0 号数据库**：
   - 你之前问的“怎么选 15 号库”，在 Cluster 模式下**不生效**。Redis Cluster 只支持 db 0。这也是为了设计简单（跨库分片太复杂）。
2. **无法支持跨槽位的多 Key 操作**：
   - 命令：`MSET key1 value1 key2 value2`
   - **问题**：如果 `key1` 算出来在节点 A，`key2` 算出来在节点 B，这个操作会直接报错。Redis Cluster 不支持跨节点的事务。
   - **解决办法 (Hash Tag)**：
     - 如果你非要让这两个 Key 在同一个节点，可以使用 `{}` 强制指定 Hash 部分。
     - 比如：`user:{100}:profile` 和 `user:{100}:orders`。
     - Redis 只会计算 `{}` 中间的内容（即 `100`）的 CRC16。这样它俩一定在同一个槽，也就一定在同一个节点。

### 总结

Redis Cluster 的原理可以概括为：

1. **分片**：用 **16384 个哈希槽** 切分数据。
2. **路由**：客户端请求 -> 计算 CRC16 -> 找槽 -> 找节点（如果找错，节点返回 **MOVED** 重定向）。
3. **高可用**：节点间用 **Gossip** 协议互通有无，Master 挂了由内部 Slave 自动顶上。

这套机制让 Redis 真正具备了存 **TB 级别数据** 的能力。









# Spring



## 1. Spring事务

好的，Spring 事务管理是 Spring 框架中**最核心、最常用**的功能之一，也是保证企业级应用数据一致性的关键。下面我将系统地讲解 Spring 事务。



### 一、 什么是事务？



在谈论 Spring 事务之前，首先要理解什么是事务。事务是一个**不可分割的数据库操作序列**，它要么**全部成功**，要么**全部失败**。它必须遵循 **ACID** 原则：

- **A (Atomicity) 原子性**：事务中的所有操作是一个整体，要么全部完成，要么全部不完成。
- **C (Consistency) 一致性**：事务必须使数据库从一个一致性状态变换到另一个一致性状态。
- **I (Isolation) 隔离性**：多个并发事务之间相互隔离，一个事务的执行不应被其他事务干扰。
- **D (Durability) 持久性**：一个事务一旦被提交，它对数据库中数据的改变就是永久性的。



### 二、 Spring 事务的核心原理：AOP



Spring 并不直接实现事务，而是对底层数据库事务（如 JDBC 事务）或 JTA 事务进行了**统一的抽象和封装**。其核心实现是基于 **AOP (面向切面编程)**。

**工作流程如下**：

1. **代理创建**：当 Spring 容器启动时，如果发现一个 Bean 的某个 `public` 方法上标注了 `@Transactional` 注解，Spring AOP 会为这个 Bean 创建一个**代理对象 (Proxy)**。
2. **方法拦截**：当外部代码调用这个 Bean 的事务方法时，实际上调用的是这个代理对象的方法。
3. **事务开启**：代理对象在**执行真实方法之前**，会先开启一个事务（`BEGIN TRANSACTION`）。
4. **执行业务逻辑**：调用真实的 Bean 方法，执行具体的业务操作。
5. **事务提交/回滚**：
   - 如果真实方法**正常执行完毕**（没有抛出异常），代理对象会**提交事务**（`COMMIT`）。
   - 如果真实方法**抛出异常**，代理对象会**回滚事务**（`ROLLBACK`）。

这个过程对开发者是完全透明的，让我们能将业务代码和事务管理代码完全解耦。



### 三、 `@Transactional` 注解详解



`@Transactional` 是实现**声明式事务**最常用的方式，它有很多重要的属性来控制事务的行为。



#### 1. `propagation` (传播行为)



这是**最重要**的属性，它定义了当一个事务方法被另一个事务方法调用时，事务应该如何传播。

- **`REQUIRED` (默认值)**：如果当前存在事务，则加入该事务；如果当前没有事务，则创建一个新的事务。这是最常见的选择。
- **`REQUIRES_NEW`**：**总是创建一个新的事务**。如果当前存在事务，则将当前事务挂起。新事务与外部事务完全独立。
- **`SUPPORTS`**：如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务的方式继续运行。
- **`NOT_SUPPORTED`**：以非事务方式运行。如果当前存在事务，则将当前事务挂起。
- **`MANDATORY`**：必须在一个已有的事务中执行，否则抛出异常。
- **`NEVER`**：必须在一个非事务的环境中执行，否则抛出异常。
- **`NESTED`**：如果当前存在事务，则创建一个嵌套事务（基于数据库的 Savepoint 实现）。如果外部事务回滚，嵌套事务也会回滚。而嵌套事务的回滚不影响外部事务。



#### 2. `isolation` (隔离级别)



定义了事务的隔离级别，用来解决并发事务中的**脏读、不可重复读、幻读**等问题。

- **`DEFAULT` (默认值)**：使用底层数据库的默认隔离级别（如 MySQL InnoDB 默认为 `REPEATABLE_READ`）。
- **`READ_UNCOMMITTED`**：读未提交。
- **`READ_COMMITTED`**：读已提交（Oracle 默认）。
- **`REPEATABLE_READ`**：可重复读（MySQL InnoDB 默认）。
- **`SERIALIZABLE`**：串行化。



#### 3. 回滚规则 (`rollbackFor`, `noRollbackFor`)



这是一个非常关键且容易出错的地方。

- **默认行为**：Spring 的事务默认只在遇到 **`RuntimeException` (运行时异常)** 或 **`Error` (错误)** 时才会进行回滚。对于**受检异常 (Checked Exception)**，**默认是不回滚的**。

- **`rollbackFor`**：指定哪些异常类型需要触发事务回滚。

  Java

  ```
  @Transactional(rollbackFor = Exception.class) // 表示任何Exception都回滚
  public void myMethod() { ... }
  ```

- **`noRollbackFor`**：指定哪些异常类型**不**需要触发事务回滚。



#### 4. `readOnly` (只读)



- 将事务设置为只读模式。这可以作为一个性能优化的提示，告诉数据库这个事务不会进行写操作。



#### 5. `timeout` (超时)



- 指定事务的超时时间（秒）。如果事务在指定时间内未完成，将被强制回滚。



### 四、 事务失效的常见场景（非常重要！）



由于 Spring 事务是基于 AOP 代理实现的，在某些情况下，代理会失效，导致事务不生效。

1. 方法不是 public：

   @Transactional 必须用在 public 方法上才能生效。因为代理模式无法拦截 protected, private 或 package-private 方法的调用。

2. 方法内部调用 (Self-Invocation)：

   最常见的失效原因。在一个类的非事务方法中，通过 this 关键字调用本类中的事务方法，事务不会生效。

   - **原因**：`this` 指向的是原始对象，而不是 Spring 创建的代理对象。调用 `this.b()` 会绕过代理，直接执行原始对象的代码，AOP 拦截自然就失效了。
   - **解决**：将事务方法移到另一个 Bean 中，通过依赖注入调用；或者注入自己代理对象再调用。

3. 异常被 catch 捕获：

   如果在事务方法内部使用了 try-catch 块捕获了异常，并且没有在 catch 块中将异常重新抛出，那么 Spring 的事务切面就无法感知到异常的发生，也就不会触发回滚。

4. 回滚规则配置错误：

   方法抛出了一个受检异常（如 IOException），但没有通过 rollbackFor 属性指定该异常需要回滚，事务也不会回滚。

5. 数据库引擎不支持事务：

   如果你的 MySQL 表使用的是 MyISAM 存储引擎，那么无论 Spring 如何配置，事务都不会生效，因为 MyISAM 本身就不支持事务。



## 2. 事务传播行为

当然可以。Spring 事务的传播行为（Transaction Propagation）是 `@Transactional` 注解中**最重要、也最能体现其灵活性的属性**。



### 什么是事务传播行为？



**一句话解释**：事务传播行为定义了当一个带有事务的方法（我们称之为**外部方法**）调用另一个也带有事务的方法（**内部方法**）时，内部方法的事务应该如何运行。例如，内部方法是应该加入外部方法的现有事务，还是应该开启一个全新的事务？

理解这一点对于设计复杂的、多服务调用的业务逻辑至关重要。

Spring 定义了七种传播行为，我们可以将它们分为三类来理解。

------



### 第一类：支持当前事务（最常用）



这类传播行为会尝试加入一个已经存在的事务。



#### 1. `PROPAGATION_REQUIRED` (默认值)



- **一句话解释**：**如果存在事务，则加入；如果不存在，则创建新的。**
- **详细说明**：
  - **外部方法有事务**：当外部方法 `A()` 调用内部方法 `B()` 时，`B()` 会**加入** `A()` 的事务，成为这个事务的一部分。它们共享同一个数据库连接，要么一起成功提交，要么一起失败回滚。
  - **外部方法无事务**：当 `A()` 没有事务时，`B()` 会为自己**创建一个新的事务**，独立地运行。
- **使用场景**：这是**最常用**的传播行为，适用于绝大多数业务场景，如增、删、改操作。它能确保一个完整的业务流程（可能跨越多个方法）被包裹在同一个事务中。



#### 2. `PROPAGATION_SUPPORTS`



- **一句话解释**：**如果存在事务，则加入；如果不存在，则以非事务方式运行。**
- **详细说明**：
  - **外部方法有事务**：`B()` 加入 `A()` 的事务。
  - **外部方法无事务**：`B()` **不会**创建新事务，它的所有数据库操作都会在非事务性的状态下执行（通常意味着自动提交）。
- **使用场景**：通常用于一些**只读**或非核心的业务方法。这些方法可以参与到一个事务中，但本身并不强制要求事务存在。



#### 3. `PROPAGATION_MANDATORY`



- **一句话解释**：**强制要求必须存在一个事务，否则抛出异常。**
- **详细说明**：
  - **外部方法有事务**：`B()` 加入 `A()` 的事务。
  - **外部方法无事务**：直接抛出异常 `IllegalTransactionStateException`。
- **使用场景**：不常用。通常用于一些核心的、必须在事务上下文中执行的工具类或内部方法，以确保它们不会被错误地在非事务状态下调用。

------



### 第二类：不支持当前事务



这类传播行为会避免在一个已存在的事务中运行。



#### 4. `PROPAGATION_REQUIRES_NEW`



- **一句话解释**：**总是创建一个全新的、独立的事务。**
- **详细说明**：
  - **外部方法有事务**：当 `A()` 调用 `B()` 时，`A()` 的事务会被**挂起（pause）**。`B()` 会开启一个**全新的、完全独立**的事务。`B()` 的事务提交或回滚，**完全不影响** `A()` 的事务。`B()` 执行完毕后，`A()` 的事务才会**恢复（resume）**。
  - **外部方法无事务**：`B()` 同样会为自己创建一个新的事务。
- **使用场景**：**非常重要**。当你希望内部方法的事务独立于外部方法，确保其操作**无论外部事务成功与否都能独立提交**时使用。
  - **经典案例**：在一个订单处理方法 `placeOrder()`（有事务）中，需要调用一个日志记录方法 `logOperation()`（也有事务）。我们希望**无论订单处理成功还是失败回滚，这条操作日志都必须成功保存到数据库**。此时就应将 `logOperation()` 的传播行为设置为 `REQUIRES_NEW`。



#### 5. `PROPAGATION_NOT_SUPPORTED`



- **一句话解释**：**以非事务方式运行，如果存在事务，则将其挂起。**
- **详细说明**：
  - **外部方法有事务**：`A()` 的事务会被挂起，`B()` 的所有数据库操作都在非事务状态下执行。
  - **外部方法无事务**：`B()` 同样在非事务状态下执行。
- **使用场景**：当你确定某个方法的数据库操作不需要事务支持，且不希望它受外部事务影响时使用。



#### 6. `PROPAGATION_NEVER`



- **一句话解释**：**强制要求必须在非事务状态下运行，否则抛出异常。**
- **详细说明**：
  - **外部方法有事务**：直接抛出异常。
  - **外部方法无事务**：正常在非事务状态下执行。
- **使用场景**：与 `MANDATORY` 相对，用于确保某个方法绝对不会被事务包裹。

------



### 第三类：嵌套事务





#### 7. `PROPAGATION_NESTED`



- **一句话解释**：**在现有事务中创建一个嵌套的子事务。**
- **详细说明**：
  - **外部方法有事务**：`B()` 会创建一个基于数据库**保存点 (Savepoint)** 的**嵌套事务**。`B()` 可以独立地回滚（回滚到保存点），而不影响 `A()`。但是，如果 `A()` 发生回滚，那么 `B()` 的所有操作也**必定会回滚**。
  - **外部方法无事务**：`B()` 的行为同 `REQUIRED`，即创建一个新事务。
- **与 `REQUIRES_NEW` 的核心区别**：
  - `REQUIRES_NEW` 创建的是一个**完全独立的物理事务**。
  - `NESTED` 创建的是一个**依赖于外部事务的子事务**。外部事务的回滚会影响它，但它的回滚不一定会影响外部事务。
- **使用场景**：用于复杂的业务场景，你希望一个子流程可以独立回滚，但又不希望它脱离主流程的整体控制。**注意**：不是所有数据库都支持保存点。



### 总结表格



| **传播行为**       | **外部有事务**               | **外部无事务**   | **核心场景**                 |
| ------------------ | ---------------------------- | ---------------- | ---------------------------- |
| **`REQUIRED`**     | **加入当前事务**             | **创建新事务**   | **绝大多数业务方法（默认）** |
| **`REQUIRES_NEW`** | **挂起当前事务，创建新事务** | 创建新事务       | **日志记录、独立业务单元**   |
| `SUPPORTS`         | 加入当前事务                 | 以非事务方式运行 | 非核心的只读方法             |
| `MANDATORY`        | 加入当前事务                 | 抛出异常         | 必须在事务中调用的工具方法   |
| `NOT_SUPPORTED`    | 挂起当前事务                 | 以非事务方式运行 | 确定不需要事务的方法         |
| `NEVER`            | 抛出异常                     | 以非事务方式运行 | 确定不能在事务中调用的方法   |
| `NESTED`           | **创建嵌套事务 (Savepoint)** | 创建新事务       | 可独立回滚的复杂子流程       |









# SpringCloud





## 1. HTTP调用与OpenFeign调用：深入解析两者差异

在现代软件开发，尤其是在微服务架构中，服务间的通信至关重要。HTTP作为互联网数据通信的基石，是实现这种通信的主要协议。然而，直接使用HTTP进行编程较为繁琐，因此涌现了许多简化操作的框架，OpenFeign便是其中之一。本文将深入探讨HTTP调用与OpenFeign调用的核心区别。



### 核心概念：协议与客户端库



首先，需要明确两者的根本不同：

- **HTTP (HyperText Transfer Protocol, 超文本传输协议)** 是一种**应用层协议**。它定义了客户端和服务器之间交换数据的格式和规则，是万维网数据通信的基础。它本身并不是一种具体的实现或代码库，而是一套标准。
- **OpenFeign** 是一个**声明式的HTTP客户端库**。它构建在HTTP协议之上，为Java开发者提供了一种更优雅、更简洁的方式来发起HTTP请求。你可以将它理解为对原生HTTP调用的一种高级封装，它使得调用远程HTTP服务就像调用本地方法一样简单。



### 主要区别详解



| **特性**               | **直接HTTP调用 (例如使用 RestTemplate 或 HttpClient)**       | **OpenFeign 调用**                                           |
| ---------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **编程模型**           | **命令式 (Imperative)**                                      | **声明式 (Declarative)**                                     |
|                        | 开发者需要手动编写代码来构建HTTP请求的各个部分，包括URL、请求头、请求体、参数等，然后执行请求并解析响应。代码通常较为冗长。 | 开发者只需定义一个接口，并使用注解来描述HTTP请求的细节（如URL、请求方法、请求头等）。框架会自动在运行时生成实现类来处理实际的HTTP通信。 |
| **代码简洁度**         | **较低**                                                     | **非常高**                                                   |
|                        | 需要编写大量样板代码（boilerplate code）来处理请求的构建、执行、错误处理和响应解析。 | 极大地减少了代码量，使得代码更易读、更易于维护。开发者可以更专注于业务逻辑而非HTTP通信的底层细节。 |
| **服务发现与负载均衡** | **需手动集成**                                               | **自动集成**                                                 |
|                        | 在微服务环境中，需要手动与服务发现组件（如Eureka, Consul）集成，以获取服务实例的地址和端口，并自行实现或集成客户端负载均衡策略（如Ribbon）。 | 与Spring Cloud生态系统无缝集成。可以自动从服务注册中心发现服务，并通过内置的负载均衡器（如Spring Cloud LoadBalancer）将请求分发到健康的服务实例上。开发者只需使用服务名即可调用，无需关心具体的IP地址和端口。 |
| **可读性与维护性**     | **较差**                                                     | **优秀**                                                     |
|                        | 请求的URL和参数散落在代码各处，难以集中管理和维护。          | 所有的API定义都集中在接口中，一目了然，非常清晰。接口本身就是一份动态的API文档。 |
| **灵活性与控制力**     | **高**                                                       | **相对较低**                                                 |
|                        | 开发者可以完全控制HTTP请求的每一个细节，适用于需要进行精细化定制和优化的复杂场景。 | 虽然提供了丰富的配置选项（如超时、重试、拦截器等），但在某些极端情况下，对底层HTTP请求的控制力不如直接调用。 |
| **错误处理**           | **需手动实现**                                               | **提供内置机制**                                             |
|                        | 需要编写`try-catch`块来处理各种网络异常和HTTP错误状态码。    | 提供了错误解码器（ErrorDecoder），可以将HTTP错误响应转化为自定义的异常，并能与断路器（如Resilience4j）结合，实现服务降级和熔断策略。 |



### 场景选择：何时使用哪种方式？



- **选择直接HTTP调用：**
  - 当你需要对HTTP请求进行极度精细的控制，例如自定义复杂的认证逻辑、处理特殊的响应格式或进行底层性能调优。
  - 在非Spring Cloud环境中，或者项目中仅需要进行少数简单的HTTP调用，引入OpenFeign可能显得过于“重”。
  - 与一些不支持标准RESTful风格的旧系统进行交互。
- **选择OpenFeign调用：**
  - 在**微服务架构**中，特别是使用**Spring Cloud**生态系统的项目，OpenFeign是进行服务间通信的首选。
  - 当项目中有大量的服务间调用时，OpenFeign可以极大地提升开发效率，降低代码复杂度和维护成本。
  - 当你希望代码更加清晰、可读，并能从服务发现和负载均衡等集成特性中受益时。



### 总结



总而言之，HTTP是一种通信协议，而OpenFeign是一个基于该协议的、用于简化开发的客户端工具。直接进行HTTP调用给予了开发者最大的灵活性和控制力，但代价是代码的复杂性和开发效率的降低。OpenFeign通过其声明式、面向接口的编程模型，将开发者从繁琐的HTTP通信细节中解放出来，尤其是在微服务架构下，其与服务治理体系的无缝集成使其成为一个强大而高效的选择。











# 系统设计



## 1. 为第三方提供API的考虑方向

好的，这是一个非常有价值的实践问题，它考察的是从一个内部功能模块，向一个对外、可靠、安全的生产级服务演进时需要具备的系统设计能力。

根据你实习中“统计列车开行情况”的工作，要向携程、飞猪这样的第三方公司提供API，你需要从**设计原则**和**具体实现方案**两个层面来考虑。

------



### **第一部分：需要考虑的方面 (设计原则)**



在编写任何代码之前，必须先思考以下几个关键方面，它们决定了你的API是否专业和可靠。

1. **安全性 (Security)**
   - **认证 (Authentication)**：我如何知道是谁在调用我？必须确保只有授权的第三方（如携程）才能访问。绝不能允许匿名访问。
   - **授权 (Authorization)**：携程调用我的API，它有哪些权限？能访问所有数据，还是只能访问部分数据？
   - **传输安全**：API必须使用 HTTPS (TLS加密) 来防止数据在传输过程中被窃听或篡改。
   - **防攻击**：需要考虑如何防止常见的Web攻击，如SQL注入、重放攻击等。
2. **性能与稳定性 (Performance & Stability)**
   - **高吞吐量**：携程、飞猪的请求量可能是巨大的。你的API必须能够处理高并发请求。
   - **低延迟**：查询列车状态这类信息，要求响应速度快。
   - **限流 (Rate Limiting)**：必须对第三方进行速率限制，防止某个调用方因为程序bug或恶意攻击，发送海量请求拖垮你的整个系统。
   - **熔断与降级**：如果你的API依赖的其他内部服务（比如数据库）出现问题，API本身不能崩溃，应该能快速失败（熔断）或返回一个兜底数据（降级）。
3. **可靠性与可用性 (Reliability & Availability)**
   - **高可用**：API服务需要集群化部署，避免单点故障。一个服务器实例宕机，不应影响整体服务。
   - **监控与告警**：需要对API的健康状况（如响应时间、错误率、请求量）进行实时监控，并在出现问题时立即告警。
4. **可维护性与易用性 (Maintainability & Usability)**
   - **清晰的文档**：必须提供非常清晰、详尽的API文档，包含每个接口的URL、参数说明、返回值示例和错误码解释。
   - **版本控制 (Versioning)**：API一旦发布，就不能随意修改。如果未来需要进行不兼容的改动，应该发布一个新的版本（如 `/v2/`），同时维护旧版本。
   - **统一的错误处理**：提供标准、一致的错误响应格式，方便调用方进行程序化处理。

------



### **第二部分：具体的实现方案**



基于以上原则，我们可以设计一套现代、标准的微服务架构方案，其中**API网关**是整个方案的核心。



#### **1. 整体架构：API网关模式**



我们不会让第三方直接调用我们的业务服务。而是在业务服务前面加一个“哨兵”——API网关。

**调用流程**：`携程/飞猪 -> API网关 -> 内部的列车信息服务`

**技术选型**：可以使用 **Spring Cloud Gateway** 或 Kong。



#### **2. 具体实现细节**



1. **认证方案：API Key + 签名 (Signature)**

   - **颁发凭证**：为每个第三方（如携程）分配一个唯一的 `appKey` 和一个更长的 `appSecret`（密钥，仅客户端和服务器知道）。
   - **调用过程**：
     1. 携程在发起请求时，将所有请求参数（包括`appKey`、时间戳`timestamp`、随机数`nonce`）按字母顺序排序。
     2. 将排序后的参数拼接成一个字符串。
     3. 使用`appSecret`对这个字符串进行 HMAC-SHA256 等算法加密，生成一个**签名 (signature)**。
     4. 将`appKey`, `timestamp`, `nonce`, 和 `signature` 全部放在请求头 (Request Header) 中发送过来。
   - **验证过程**：你的 **API网关** 收到请求后，用同样的方式在服务器端生成一遍签名，与携程传过来的签名进行比对。如果一致，则认证通过；不一致则拒绝。
   - **优点**：可以有效防止请求被篡改和重放攻击。

2. **限流方案：令牌桶算法**

   - 在 **API网关** 层，集成**Redis**来实现限流。
   - **实现**：Spring Cloud Gateway 提供了基于 Redis 的 `RequestRateLimiter`，可以非常方便地配置。我们可以为不同的 `appKey` 设置不同的速率，比如允许携程每秒1000次请求，而其他小程序每秒100次。

3. **API 设计：RESTful 风格与版本控制**

   - **URL设计**：采用清晰的 RESTful 风格，并将版本号放入URL中。

     - 查询特定车次状态: `GET /v1/trains/status?trainNumber=G250`
     - 查询某站点的出发车次: `GET /v1/stations/beijing/departures?date=2025-10-16`

   - **响应格式**：设计统一的JSON响应体。

     JSON

     ```
     {
       "code": 0, // 0表示成功，其他表示错误
       "message": "Success",
       "data": { // 业务数据
         "trainNumber": "G250",
         "status": "On Time",
         "currentLocation": "Jinan West"
       }
     }
     ```

   - **分页**：对于返回列表的接口，使用 `page` 和 `pageSize` 参数进行分页。

4. **缓存策略**

   - 对于不经常变化的数据（如某车次一天的固定时刻表），可以在业务服务中加入 **Redis 缓存**，极大地减轻数据库压力。
   - 对于实时性要求高的数据（如“晚点5分钟”），可以设置一个非常短的缓存时间（如10-30秒），或者不缓存。

5. **文档方案：Swagger / OpenAPI**

   - 在你的 Spring Boot 业务服务中，集成 Swagger (OpenAPI 3) 依赖。
   - 通过在 Controller 的接口上添加注解，可以自动生成一个交互式的API文档网站。将这个网站地址提供给第三方即可。

通过这一整套“**API网关 + 签名认证 + Redis限流缓存 + Swagger文档**”的方案，你就可以构建出一个安全、高性能且专业的对外API服务了。  




























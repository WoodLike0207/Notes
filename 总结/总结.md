# Redis



## 1.  Redisson 分布式锁的实现原理

Redisson 是一个基于 Redis 的 Java 驻内存数据网格（In-Memory Data Grid）。它提供的分布式锁是其最著名的功能之一，相比于自己基于 `SETNX` 等命令实现的简易分布式锁，Redisson 的锁功能更加健壮和完善。

其核心实现原理可以概括为以下几点：

1. **基于 Hash 数据结构存锁信息**
2. **利用 Lua 脚本保证操作原子性**
3. **巧妙的 Watchdog（看门狗）机制实现锁的自动续期**
4. **支持可重入锁和公平锁等高级特性**

下面我们来详细解析这几个核心环节。



### 1. 加锁 (Lock) 的实现

当你调用 `RLock lock = redisson.getLock("myLock"); lock.lock();` 时，Redisson 内部会执行一段精心设计的 Lua 脚本。

与很多人想象的不同，Redisson 并非简单地使用 `SETNX` 命令。它采用的是 Redis 的 **Hash** 数据结构。一个锁在 Redis 中会以一个 Hash 键的形式存在，例如键名为 `myLock`。

这个 Hash 结构中主要包含两个字段：

- **锁的持有者标识**：一个唯一的ID，通常是 `UUID:threadId`，用来标识哪个客户端的哪个线程持有了这个锁。
- **重入次数 (reentrancy count)**：一个计数器，用于实现可重入锁的逻辑。

**加锁的 Lua 脚本逻辑大致如下 (伪代码):**

Lua

```lua
-- KEYS[1] 是锁的 Key，例如 "myLock"
-- ARGV[1] 是锁的过期时间（毫秒）
-- ARGV[2] 是锁的持有者标识，例如 "uuid:threadId"

-- 1. 判断锁是否存在
if (redis.call('exists', KEYS[1]) == 0) then
    -- 1.1. 锁不存在，直接获取锁
    redis.call('hset', KEYS[1], ARGV[2], 1); -- 设置持有者和重入次数为1
    redis.call('pexpire', KEYS[1], ARGV[1]); -- 设置过期时间
    return nil; -- 返回 nil 表示加锁成功
end;

-- 2. 判断锁是否被当前线程持有
if (redis.call('hexists', KEYS[1], ARGV[2]) == 1) then
    -- 2.1. 锁已存在，且是当前线程持有，实现可重入
    redis.call('hincrby', KEYS[1], ARGV[2], 1); -- 重入次数+1
    redis.call('pexpire', KEYS[1], ARGV[1]); -- 重新设置过期时间
    return nil; -- 返回 nil 表示加锁成功
end;

-- 3. 锁已存在，且被其他线程持有，加锁失败
return redis.call('pttl', KEYS[1]); -- 返回锁的剩余过期时间
```

为什么使用 Lua 脚本？

因为 Redis 执行 Lua 脚本是原子性的。上述“判断-操作-设置过期”等一系列操作会被当作一个不可分割的整体来执行，杜绝了并发场景下可能出现的竞态条件。如果单纯用多个命令组合，在分布式环境下，执行到一半时可能会出现问题。



### 2. Watchdog（看门狗）自动续期机制



这是 Redisson 分布式锁最核心、最巧妙的设计，它解决了“业务执行时间超过锁的过期时间而被动释放锁”的致命问题。

**工作原理：**

1. **加锁成功后启动**：当一个线程成功获取到锁之后，如果用户没有显式指定锁的过期时间（即调用 `lock()` 而不是 `lock(leaseTime, unit)`），Redisson 会默认设置一个30秒的过期时间，并**在后台启动一个定时任务**，这就是“看门狗”。
2. **定时检查与续期**：这个看门狗是一个后台线程，它会**每隔10秒**（默认是 `lockWatchdogTimeout / 3`）检查一下持有锁的客户端线程是否还存在。如果线程还存在（意味着业务逻辑还没执行完），看门狗就会**重新将锁的过期时间设置为30秒**。
3. **业务完成时停止**：当持有锁的线程执行完业务逻辑，调用 `unlock()` 方法释放锁时，会取消这个后台的定时任务。
4. **宕机情况**：如果持有锁的客户端不幸宕机，它无法正常释放锁。但由于看门狗线程也随之消失，不会再为这个锁续期。因此，这个锁会在最多30秒后自动过期，从而避免了死锁的产生。

**总结：** 看门狗机制通过在后台不断“续命”的方式，保证了只要业务逻辑没有执行完毕，锁就不会因为超时而释放，极大地提高了分布式锁的可靠性。



### 3. 解锁 (Unlock) 的实现



解锁操作同样是通过一段 Lua 脚本来保证原子性。

**解锁的 Lua 脚本逻辑大致如下 (伪代码):**

Lua

```lua
-- KEYS[1] 是锁的 Key
-- ARGV[1] 是 unlock 消息（用于发布/订阅，后面解释）
-- ARGV[2] 是锁的持有者标识 "uuid:threadId"

-- 1. 判断锁是否存在，以及是否由当前线程持有
if (redis.call('hexists', KEYS[1], ARGV[2]) == 0) then
    return nil; -- 锁不存在或不是自己持有的，直接返回
end;

-- 2. 是自己持有的锁，将重入次数-1
local counter = redis.call('hincrby', KEYS[1], ARGV[2], -1);

-- 3. 判断重入次数是否已降为0
if (counter > 0) then
    -- 3.1. 计数器还大于0，说明还在重入状态，不能删锁，只更新过期时间
    redis.call('pexpire', KEYS[1], ARGV[3]); -- ARGV[3] 是新的过期时间
    return 0;
else
    -- 3.2. 计数器为0，可以安全删除锁
    redis.call('del', KEYS[1]);
    -- 并且发布一个 "unlock" 消息，通知其他等待的线程可以尝试获取锁了
    redis.call('publish', KEYS[1] .. ':unlock_message', ARGV[1]);
    return 1;
end;
```



### 4. 阻塞与唤醒机制 (可中断锁)



当一个线程尝试加锁失败时（`lock.lock()`），它如何“阻塞”等待呢？

Redisson 利用了 Redis 的 **Pub/Sub (发布/订阅)** 机制。

1. **订阅**：尝试加锁失败的线程，会订阅一个与锁的 Key 相关的特定 channel（例如 `redisson_lock__channel__{myLock}`）。
2. **等待**：订阅后，线程会进入一个循环，不断地尝试获取锁，并在失败后通过一个 `Semaphore` 或 `CountDownLatch` 陷入等待状态，等待被唤醒或超时。
3. **发布（唤醒）**：当持有锁的客户端调用 `unlock()` 方法时，除了会删除锁的 Key，还会向上述 channel **发布一条 "unlock" 消息**。
4. **接收与尝试**：所有订阅了该 channel 的等待线程都会收到这条消息，然后被唤醒，从等待状态中出来，重新开始新一轮的尝试加锁。

这种基于发布订阅的机制，避免了像 `while(true)` 循环不断请求 Redis 的 “忙等” 模式，减少了对 Redis 服务器的无用压力，更加高效。



### 总结

Redisson 分布式锁的实现原理是一个精巧的组合：

- **数据层面**：使用 Hash 结构存储锁信息，支持了**可重入**特性。
- **原子性保障**：核心的加锁和解锁逻辑都封装在 **Lua 脚本**中，由 Redis 服务端原子性执行，杜绝了并发问题。
- **高可用性**：通过**看门狗（Watchdog）机制**，实现了锁的自动续期，有效防止了因业务执行时间过长导致的锁失效问题，避免了把别人的锁误删的风险。
- **高性能等待**：利用 Redis 的**发布/订阅机制**实现了异步的、低功耗的等待/唤醒逻辑，避免了客户端的空转和对 Redis 的无效轮询。

正是这些设计的结合，使得 Redisson 的分布式锁成为目前业界公认的、功能最完善、最可靠的实现之一。



## 2. RDB原理

这也是面试官非常喜欢考察**底层操作系统原理**的一个知识点。

**RDB (Redis Database)** 是 Redis 的默认持久化方式。它的核心概念是**“快照” (Snapshot)**。

就好比你给当下的数据库拍了一张“照片”。这张照片里包含了这一时刻所有的键值对数据，并将其保存为一个二进制文件（默认为 `dump.rdb`）。

面试中，你不能只回答“它是快照”，你必须深入讲清楚**“它是如何在不阻塞主线程的情况下，一边修改数据，一边拍照的？”**

这就引出了 RDB 的核心原理：**`fork` 子进程** 和 **写时复制 (Copy-On-Write, COW)**。

------

### 1. 触发方式：谁在按快门？

RDB 有两种触发方式：

1. **手动触发**：
   - `SAVE`：**绝对不要在生产环境用！** 它会让主线程执行保存操作，阻塞所有客户端请求，直到保存完成。
   - `BGSAVE` (Background Save)：Redis 会在后台异步进行快照操作，主线程可以继续处理命令。
2. **自动触发**：
   - 在 `redis.conf` 中配置 `save m n`（例如 `save 900 1`：900秒内有1个key改变就触发）。
   - **注意：** 自动触发实际上调用的也是 `BGSAVE`。
   - 此外，执行 `FLUSHALL` 命令或 Redis 正常 `SHUTDOWN` 时，也会自动生成 RDB。

------

### 2. 核心原理：`fork` 与 Copy-On-Write (COW)

这是 RDB 最精髓的部分。

当 Redis 执行 `BGSAVE` 时，流程如下：

1. **Fork 子进程（关键阻塞点）**：
   - Redis 主进程（Parent）调用操作系统的 `fork()` 系统调用，创建一个子进程（Child）。
   - **注意**：`fork` 并不是把所有内存数据 copy 一份给子进程（那样太慢了）。它**只拷贝了页表 (Page Table)**。
   - **页表**记录了“虚拟内存地址”到“物理内存地址”的映射关系。
   - **耗时**：虽然只拷页表，但如果 Redis 内存很大（比如 10GB），拷贝页表也需要毫秒级的时间。**在这段时间内，主线程是阻塞的**。
2. **子进程写数据**：
   - `fork` 完成后，主线程恢复响应客户端请求。
   - 子进程读取内存数据，将其写入临时的 RDB 文件。
   - 写完后，用临时文件替换旧的 RDB 文件。
3. **写时复制 (Copy-On-Write) 技术**：
   - **问题**：子进程在写磁盘的时候（可能需要几分钟），主进程还在修改数据怎么办？如果主进程改了数据，子进程读到的不就乱了吗？
   - **解决**：操作系统使用 **COW** 机制。
     - `fork` 之后，父子进程**共享**物理内存（指向同一块物理地址），且权限被设置为 **Read-Only (只读)**。
     - **读数据**：大家相安无事，一起读。
     - **写数据**：当主进程（Parent）想要**修改**某个 key（比如 Key A）时，CPU 检测到内存页是只读的，会触发缺页中断。
     - **复制**：操作系统会把 Key A 所在的**物理内存页 (Page)** 复制一份副本给主进程。
     - **分离**：主进程在**副本**上修改数据，子进程继续读取**原版**数据。
     - **结果**：子进程看到的依然是 `fork` 那一瞬间的数据（快照的含义），完全不受主进程后续修改的影响。

------

### 3. RDB 的优缺点（面试必考）

在面试中，通常需要对比 RDB 和 AOF。

**✅ 优点：**

1. **恢复速度极快**：RDB 是紧凑的二进制文件，Redis 重启时直接加载进内存即可。比 AOF（回放命令）快得多。
2. **文件体积小**：适合做冷备份（比如每天备份一次传到 AWS S3）。
3. **性能最大化**：主进程除了 `fork` 一下，基本不参与磁盘 I/O，全交给子进程。

**❌ 缺点：**

1. **数据丢失风险大**：
   - RDB 是间隔触发的（比如 5 分钟一次）。如果 Redis 在第 4 分 59 秒宕机，**这 5 分钟的数据全丢了**。
2. **资源消耗**：
   - `fork` 属于重操作，消耗 CPU。
   - **Copy-On-Write 导致的内存膨胀**：如果在快照期间，Redis 遭遇了极其密集的**写操作**，理论上所有共享的内存页都会被复制一份，导致 Redis 占用内存瞬间**翻倍**。这可能导致 OOM（内存溢出）。

------

### 4. 常见面试坑题

**Q1: `BGSAVE` 执行期间，Redis 会阻塞吗？**

- **答**：会，但只会阻塞在 `fork` 阶段（拷贝页表时）。`fork` 完成后，主线程就不阻塞了。除非内存非常大，否则这个时间很短。

**Q2: 为什么 Redis 不直接用多线程来做持久化，而要用多进程 (`fork`)？**

- **答**：为了**避免锁竞争**。如果用多线程，主线程和持久化线程同时访问内存，必须加锁来保证数据一致性，这会严重拖慢性能。而使用多进程 + COW，利用操作系统的内存隔离机制，实现了“无锁”的快照。

**Q3: 如果我在 `BGSAVE` 期间插入了新数据，这些数据会被保存到这次的 RDB 文件里吗？**

- **答**：**不会**。因为 COW 机制，子进程看到的是 `fork` 那一瞬间的数据。新数据要等下一次 RDB 才能被保存。

------

### 总结

学习 RDB 原理，核心在于理解 **`fork` (阻塞点)** 和 **COW (如何实现一致性视图)**。



## 3. AOF

既然理解了 RDB 的“快照”模式，那理解 **AOF (Append Only File)** 就非常容易了。

如果说 RDB 是**“照相机”**（定期给数据库拍张照片），那么 AOF 就是**“记账本”**（流水账）。

AOF 不会存“数据本身的样子”，而是把 Redis 执行过的所有**写操作命令**（如 `SET`, `DEL`, `INCR`）按顺序追加到一个文件中（默认叫 `appendonly.aof`）。

当 Redis 重启时，它只要把这个文件里的命令**从头到尾再执行一遍**（Replay），就能恢复数据。

以下是 AOF 的面试核心知识体系：

------

### 1. 核心机制：写后日志 (Write After Log)

这是 Redis AOF 与 MySQL (Write Ahead Log, WAL) 最大的不同，也是**面试常考点**。

- **MySQL (WAL)：** 先写日志，再写磁盘数据。（保命要紧，防崩溃）。
- **Redis (AOF)：** **先执行命令，把数据写到内存，然后再写日志。**

**为什么 Redis 要“反其道而行之”？**

1. **避免语法检查开销**：如果先写日志，Redis 得先检查这命令语法对不对。先执行命令，只要执行成功了，写入日志的肯定是对的。
2. **不阻塞当前写操作**：写日志是磁盘 I/O，比较慢。如果先写日志，会拖慢当前这条命令的响应速度。

**风险是什么？**

- 如果在“命令执行完”和“写日志”之间，Redis 宕机了，**这条命令就丢了**。

------

### 2. 三种刷盘策略（appendfsync）

AOF 并不是每次写入都直接刷到磁盘（那太慢了），而是先写到操作系统的 `Page Cache`（OS Buffer）里。什么时候真正刷到硬盘（fsync），由策略决定。

这是**必考配置**，你必须记住这三个单词：

| **策略**     | **配置名 (appendfsync)** | **描述**                                           | **优点**                     | **缺点**                         |
| ------------ | ------------------------ | -------------------------------------------------- | ---------------------------- | -------------------------------- |
| **Always**   | `always`                 | **同步写回**。每执行一个写命令，立刻强刷磁盘。     | **数据最安全**（基本不丢）。 | **性能最差**（吞吐量低）。       |
| **Everysec** | `everysec`               | **每秒写回**。默认配置。每秒由后台线程刷一次盘。   | **折中方案**。性能接近 RDB。 | **最多丢 1 秒数据**。            |
| **No**       | `no`                     | **操作系统控制**。Redis 不管，由 OS 决定何时刷盘。 | 性能最好。                   | **不可控**。宕机可能丢很多数据。 |

> **面试金句：** “在生产环境中，我们通常使用默认的 `everysec`，因为它在性能和安全性之间取得了最好的平衡。最多只丢失一秒的数据，这是大多数业务可以接受的。”

------

### 3. AOF 重写 (Rewrite) —— 给日志“瘦身”

问题：

AOF 是追加写的，文件会越来越大。

比如你执行了 100 次 INCR count，最终 count 是 100。

- AOF 文件里存了 **100 条** `INCR` 命令。
- 但其实恢复数据时，我只需要 1 条 `SET count 100` 就够了。

解决：AOF 重写 (BGREWRITEAOF)

Redis 会定期启动一个子进程，把内存里的数据“转化”为最精简的写命令，存到一个新的 AOF 文件中，然后替换旧文件。

面试大坑：重写是去分析旧的 AOF 文件吗？

答：绝对不是！

重写的时候，Redis 根本不理旧的 AOF 文件。它是直接读取当前内存里的数据，然后生成构建这些数据所需的命令。

- 比如内存里 `count = 100`，重写子进程就直接向新文件写入 `SET count 100`。

**重写流程（与 RDB 惊人地相似）：**

1. **Fork 子进程**：主线程 `fork` 出一个子进程（这里也会阻塞，也有 Copy-On-Write）。
2. **子进程写新文件**：子进程遍历内存，把数据转成命令写入新的临时 AOF 文件。
3. **AOF 重写缓冲区 (AOF Rewrite Buffer)**：
   - **关键点**：在子进程重写的过程中，主线程依然在接收新命令。
   - 新命令除了写入“旧 AOF 缓冲区”，还会写入一个专门的 **“AOF 重写缓冲区”**。
4. **追加与替换**：
   - 子进程写完新文件后，通知主线程。
   - 主线程把“AOF 重写缓冲区”里的累积命令，追加到新文件末尾。
   - 用新文件替换旧文件。

------

### 4. RDB vs AOF：终极对决

| **特性**       | **RDB (快照)**                    | **AOF (日志)**            |
| -------------- | --------------------------------- | ------------------------- |
| **文件体积**   | 小（二进制压缩）                  | 大（文本命令）            |
| **恢复速度**   | **极快** (直接加载内存)           | **慢** (要一条条重放命令) |
| **数据安全性** | 低 (丢一段时间)                   | **高** (默认丢 1 秒)      |
| **优先级**     | 低 (若有 AOF，Redis 优先加载 AOF) | **高** (数据更全)         |

------

### 5. Redis 4.0 混合持久化 (Hybrid Persistence)

这是现在的**主流方案**。

**痛点：**

- RDB 丢数据太多。
- AOF 恢复太慢（如果文件有 10GB，回放要很久）。

解决：

Redis 4.0 引入了混合持久化。在 AOF 重写 时：

1. 子进程先把当前内存数据做成 **RDB 快照**，写入新的 AOF 文件头部。
2. 重写期间的新命令，以 **AOF 格式** 追加在文件尾部。

**结果：** `appendonly.aof` 文件 = **[ RDB 格式数据 ] + [ AOF 格式增量日志 ]**

**优点：**

- **快**：前半段是 RDB，加载极快。
- **全**：后半段是 AOF，保证数据不丢失。

### 总结

如果面试官问：“你会怎么配置 Redis 的持久化？”

**标准回答：**

> “在生产环境中，如果你对数据安全性有要求，不要只用 RDB，因为会丢数据。
>
> 也不建议单独用 AOF，因为恢复慢。
>
> 最佳实践是开启 Redis 4.0 的混合持久化功能。
>
> 也就是：开启 AOF，策略设为 everysec，同时开启 aof-use-rdb-preamble yes（混合持久化）。
>
> 这样既保证了数据最多只丢 1 秒，又能利用 RDB 格式实现快速重启恢复。”



## 4. AOF 缓冲区 和  AOF 重写缓冲区

这是一个非常棒的追问！能问出这两个 Buffer 的区别，说明你已经在脑海里构建 AOF 重写的动态过程了。

这两个 Buffer 确实很容易混淆，因为它们都存的是**“写操作命令”**，而且在 AOF 重写期间，它们甚至是**同时工作**的。

如果不搞清楚它俩的关系，就无法理解 **“为什么 Redis 重写 AOF 时，既不阻塞主线程，又不会丢数据？”**

我们把场景设定在：**Redis 正在进行 AOF 重写 (BGREWRITEAOF)** 的过程中。

------

### 1. 角色介绍

#### 🅰️ AOF 缓冲区 (`aof_buf`) —— "常规部队"

- **身份**：这是 Redis AOF 机制**一直存在**的缓冲区，跟有没有重写无关。
- **职责**：为了减少磁盘 I/O，Redis 先把写命令暂存在这里，然后根据策略（`always`/`everysec`/`no`）刷入**旧的（当前的）AOF 文件**。
- **目标文件**：`appendonly.aof` (当前正在使用的旧文件)。

#### 🅱️ AOF 重写缓冲区 (`aof_rewrite_buf`) —— "特种部队"

- **身份**：**只有在 AOF 重写期间**才会分配和使用的临时缓冲区。
- **职责**：保存**从重写开始那一刻起**，主线程接收到的**所有新写命令**。
- **目标文件**：`temp-rewriteaof-bg-pid.aof` (子进程正在生成的那个新文件)。

------

### 2. 为什么需要两个？(核心流程图解)

让我们来看一下 AOF 重写期间的时间线，你会发现这两个 Buffer 是如何“双管齐下”的：

#### 第一阶段：重写开始 (Fork)

- **时刻 T1**：主线程执行 `fork()`，创建子进程。
- **子进程**：拿着 T1 时刻的内存快照，开始乖乖地往**新 AOF 文件**里写数据（把内存数据转成命令）。
- **主线程**：继续接收客户端的新写请求（比如 `SET k v`）。

#### 第二阶段：重写进行中 (双写机制)

这是最关键的时刻！

当主线程接收到新命令 SET k v 时，为了保证数据绝对不丢，它会同时做两件事：

1. **写入 `aof_buf`**：
   - 像往常一样，把命令写入常规缓冲区，然后刷到**旧 AOF 文件**。
   - **为什么？（保命）**：万一重写过程中机器断电了，或者重写失败了，**旧的 AOF 文件必须是最新的**，这样重启时才能恢复数据。所以旧的日志流程不能停。
2. **写入 `aof_rewrite_buf`**：
   - 把同样的命令，拷贝一份写入 **AOF 重写缓冲区**。
   - **为什么？（追赶）**：子进程只有 T1 时刻的数据。T1 之后的新数据，子进程是不知道的。我们需要把这些新数据先“攒”在这个缓冲区里，等子进程写完了，再补给新文件。

#### 第三阶段：重写完成 (拼接)

1. **子进程**：终于把 T1 时刻的内存数据写完了，发信号通知主线程。
2. **主线程**：收到信号，暂停处理客户端请求（这里会短暂阻塞一下）。
3. **追加**：主线程把 **`aof_rewrite_buf`** 里的积压命令，一次性追加写入到 **新 AOF 文件** 的末尾。
4. **替换**：用新文件原子替换旧文件。

------

### 3. 一个通俗的类比

想象你在**手抄整理**一本非常乱的账本（旧 AOF），目的是整理出一本精简的新账本（新 AOF）。

1. **Fork**：你（子进程）把现在的账本拍了张照，找了个安静的房间开始照着照片抄写（重写）。
2. **业务不停**：但在你抄写的时候，老板（主线程）还在不断地接新订单。
3. **双写 (两个 Buffer)**：
   - **Buffer 1 (`aof_buf`)**：老板把新订单照常写在**那本旧的乱账本**后面。
     - *原因*：万一你抄到一半着火了（宕机），旧账本还在，记录没丢。
   - **Buffer 2 (`aof_rewrite_buf`)**：老板同时把新订单写在一张**便利贴**上。
     - *原因*：你那是照着老照片抄的，没有这些新订单。
4. **合并**：等你抄完了，老板拿着那张**便利贴**（重写缓冲区），把你没抄进去的新订单，贴到**新账本**的最后面。
5. **完成**：扔掉旧账本，启用新账本。

------

### 4. 面试中的深度追问

**Q1: 如果 `aof_rewrite_buf` 占用内存过大怎么办？**

- 这确实是个风险。如果重写过程中写流量极其巨大，这个缓冲区会无限膨胀，可能导致 OOM。
- Redis 7.0 引入了 **Multi-Part AOF**（多文件 AOF），对这块机制做了优化，不过原理大体相同。

**Q2: 为什么追加 `aof_rewrite_buf` 到新文件时，要阻塞主线程？**

- 因为这个动作必须由主线程来做（子进程已经结束了）。
- 如果不阻塞，一边追加，一边又有新数据进来，那就永远追加不完了（永远追不上）。
- 通常这个缓冲区不会特别大，追加过程是毫秒级的。

**Q3: 这两个 Buffer 里的数据是一样的吗？**

- **格式是一样的**（都是 RESP 协议的命令文本）。
- **内容也是一样的**（都是重写期间发生的新写操作）。
- 只是**用途**和**去向**不同。

### 总结

- **`aof_buf`**：保证**旧文件**的完整性，防止重写失败导致数据丢失。
- **`aof_rewrite_buf`**：保证**新文件**的数据一致性，填补重写期间产生的数据空缺。
- **关键机制**：重写期间的**双写**策略。



## 5. 主从同步原理

这确实是 Redis 复制机制中最容易混淆，但也是含金量最高的细节。面试官问这两个 Buffer，通常是为了考察你对**“全量同步 vs 增量同步”**以及**“OOM（内存溢出）风险”**的深度理解。

我们把 Redis 主从同步的整个过程拆解开，把这两个 Buffer 放到具体的场景里去讲，你一下子就明白了。

------

### 同步的三种状态

Redis 的主从同步主要分为三个阶段：

1. **全量复制 (Full Sync)**：第一次握手，或者严重滞后时。
2. **命令传播 (Command Propagate)**：正常运行时的实时同步。
3. **增量复制 (Partial Sync)**：网络抖动短暂断开后的“补发数据”。

这两个 Buffer 就在这三个阶段中扮演不同的角色。

------

### 1. 角色一：Replication Buffer (复制缓冲区)

**一句话定义**：它是**每个 Slave 独有的**、用于存放“待发送给该 Slave 的命令”的队列。

#### 它的本质

在 Redis 内部，**每一个**连接到 Master 的客户端（无论是普通的 Java 客户端，还是作为客户端的 Slave），Master 都会为其分配一个 **Client Output Buffer（客户端输出缓冲区）**。

- 当这个客户端是 Slave 时，我们习惯称之为 `replication buffer`。
- **注意**：如果有 10 个 Slave，Master 上就会有 **10 个** `replication buffer`。

#### 它在什么时候用？

**场景 A：全量同步期间（最关键）**

1. Master 执行 `BGSAVE` 生成 RDB 文件。
2. **关键点：** 在生成 RDB 和传输 RDB 的这段时间（可能几秒到几分钟），Master 依然在接收前端的写请求。
3. Master 不能把这些新写的命令丢掉，否则 Slave 加载完 RDB 就少数据了。
4. Master 会把这些**新来的写命令**存入该 Slave 对应的 `replication buffer` 中。
5. 等 RDB 传完，Master 再把这个 Buffer 里的命令发给 Slave。

**场景 B：正常命令传播期间**

- Master 接收到一个写命令 `SET k v`。
- Master 把它写入自己的内存，然后把这个命令塞进所有 Slave 的 `replication buffer`。
- 通过网络发送给 Slave。

#### 它的隐患 (OOM & 复制风暴)

如果 `replication buffer` 里的数据积压太多，超过了限制（`client-output-buffer-limit slave`），Master 会强制断开与 Slave 的连接。

- **后果**：Slave 断开后重连，又触发全量同步 -> 再次积压 Buffer -> 再次断开。这就是**“死循环”**。
- **原因**：通常是因为 RDB 太大、网络太慢、或者 Master 写请求太猛。

------

### 2. 角色二：repl_backlog_buffer (复制积压缓冲区)

**一句话定义**：它是**所有 Slave 共享的**、一个**固定大小**的**环形缓冲区 (Ring Buffer)**。

#### 它的本质

- Master 上**只有一个** `repl_backlog_buffer`，无论有多少个 Slave。
- 它默认比较小（比如 1MB，由 `repl-backlog-size` 控制）。
- 它是“先进先出”的，写满了就会覆盖最早的数据（环形覆盖）。

#### 它在什么时候用？—— 增量复制 (Partial Sync)

当 Slave 和 Master 的网络抖动了一下（断开了一小会儿），Slave 重新连上 Master。

Slave 说：“大哥，我之前的 offset 是 1000，我掉线了，能把 1000 以后的数据补给我吗？”

Master 会去检查 `repl_backlog_buffer`：

- **情况 1 (Happy Path)**：Master 发现 `offset` 1000 后的数据还在这个环形缓冲区里（没被新数据覆盖）。
  - **动作**：Master 直接把缓冲区里 1000 之后的数据发给 Slave。
  - **结果**：**增量复制**（速度极快，不需要 RDB）。
- **情况 2 (Sad Path)**：Master 发现数据更新太快，环形缓冲区转了一圈，把 `offset` 1000 的数据已经覆盖掉了（现在的最小 offset 已经是 2000 了）。
  - **动作**：Master 两手一摊：“你来晚了，数据丢了。”
  - **结果**：只能触发**全量复制**（BGSAVE -> RDB）。

------

### 3. 终极对比：两个 Buffer 谁是谁？

这是面试时的**杀手级**总结表格：

| **特性**     | **Replication Buffer**                          | **Repl_backlog_buffer**                          |
| ------------ | ----------------------------------------------- | ------------------------------------------------ |
| **存在数量** | **每个 Slave 一个** (N 个)                      | **Master 全局唯一** (1 个)                       |
| **存在形式** | 链表/队列 (内存可动态增长)                      | **环形缓冲区** (固定大小)                        |
| **主要用途** | 存放发给 Slave 的命令 (全量期间积压 + 实时转发) | 应对网络抖动，实现**增量同步**                   |
| **生命周期** | Slave 连接断开即销毁                            | Master 启动后一直存在                            |
| **内存风险** | **高**。如果积压过多会导致 OOM 或连接断开。     | **低**。固定大小，只会覆盖旧数据，不会撑爆内存。 |
| **决定因素** | 决定了全量同步能否成功                          | 决定了断线重连后能否走“增量复制”                 |

------

### 4. 完整的同步流程（串联起来）

现在我们用这两个概念把整个流程串一遍：

1. **建立连接**：Slave 启动，发送 `PSYNC`。
2. **判定**：
   - 如果是第一次连接 -> **全量复制**。
   - 如果是重连，检查 `repl_backlog_buffer`。如果在范围内 -> **增量复制**；否则 -> **全量复制**。
3. **全量复制阶段**：
   - Master `BGSAVE` 生成 RDB。
   - **关键**：Master 继续接收写请求，写到内存，同时写到 **`repl_backlog_buffer`**，并且写到该 Slave 的 **`replication buffer`**。
   - Master 发送 RDB 给 Slave。
   - Master 发送 **`replication buffer`** 里的积压命令给 Slave。
4. **命令传播阶段** (正常运行)：
   - Master 接收写命令 `SET a 1`。
   - Master 把 `SET a 1` 写到 **`repl_backlog_buffer`** (为了防备未来 Slave 断连)。
   - Master 把 `SET a 1` 写到所有 Slave 的 **`replication buffer`**，通过网络发出去。

------

### 5. 假如你是架构师（面试实战）

面试官可能会问：**“由于网络不好，我的 Redis 经常触发全量同步，导致性能很差，怎么优化？”**

基于上面的原理，你有两个调优方向：

1. **调大 `repl-backlog-size`**：
   - 原理：增大环形缓冲区的大小。
   - 效果：让积压缓冲区能容纳更长时间的数据。即使网络断开 1 分钟，offset 还没被覆盖，依然可以用增量复制，避免全量复制。
   - *比如：网络偶尔断 60s，你的 QPS 是 1000，每条命令 1KB。那你至少需要 60 \* 1000 \* 1KB = 60MB 的 backlog。*
2. **调大 `client-output-buffer-limit slave`**：
   - 原理：允许 `replication buffer` 积压更多数据。
   - 效果：防止在全量复制传输 RDB 期间，因为积压命令过多导致 Master 主动断开 Slave，从而避免陷入“全量复制 -> 失败 -> 重试”的死循环。



## 6. Redis集群原理

这绝对是 Redis 进阶面试中的**终极 Boss**。

我们之前讲的哨兵（Sentinel），解决了“高可用”问题（Master 挂了有人顶上）。

但哨兵架构有一个致命的天花板：它依然是单机写入。

无论你有多少个 Slave，写请求只能打到 Master 一个节点上。如果你的业务要做类似于“双十一”的秒杀，或者 Bilibili 那样海量的弹幕写入，单机内存（比如 64GB）和单机 CPU 很快就会成为瓶颈。

**Redis Cluster（集群）** 就是为了打破这个天花板而生的。它实现了 **分布式存储（Sharding/分片）**，让多台机器同时承担写入和存储。

我们把它拆解为 **3 个核心原理** 来讲。

------

### 1. 核心数据分布：哈希槽 (Hash Slot)

这是面试官最喜欢问的：“Redis Cluster 是怎么分片的？是一致性哈希吗？”

答：不是一致性哈希，而是哈希槽。

Redis Cluster 将整个数据库划分为 **16384** 个小格子，这些格子就叫 **哈希槽 (Hash Slot)**。

#### 分布算法

当你存一个 Key（比如 `SET user:100 "Alice"`）时，Redis 不会随便找个节点存，而是按以下公式计算：

$$Slot = CRC16(key) \pmod{16384}$$

1. 对 Key 进行 CRC16 算法计算。
2. 对 16384 取模，得到一个 0 ~ 16383 之间的数字。
3. 这个数字对应哪个节点，数据就存到哪个节点。

#### 槽位分配

假设你的集群有 3 个 Master 节点（A, B, C）：

- **节点 A** 负责：0 ~ 5460 号槽。
- **节点 B** 负责：5461 ~ 10922 号槽。
- **节点 C** 负责：10923 ~ 16383 号槽。

> 面试坑题：为什么是 16384 个槽？
>
> (这是一个加分项)
>
> 作者 Antirez 解释过：在 Redis 节点间通信（Gossip 协议）时，需要携带自己负责的槽位信息（Bitmap）。
>
> - 16384 个槽 = 16k 位 = 2KB 数据。这是心跳包大小和网络带宽的平衡点。
> - 如果用 65536 (CRC16 的最大值)，心跳包会变大到 8KB，在频繁通信时太占带宽。
> - 而且 Redis Cluster 官方建议节点数不超过 1000 个，16384 对于 1000 个节点来说足够均匀了。

------

### 2. 核心交互：去中心化 & 重定向 (MOVED / ASK)

Redis Cluster 是 无中心架构 (P2P)。也就是说，没有一个类似于 Nginx 的“代理节点”在前面分发请求。

客户端（比如你的 Java 代码）可以直接连接集群中的任意一个节点。

但是，如果我要查 `user:100`，我连接的是节点 A，但 `user:100` 算出来的槽位其实在节点 B 上，怎么办？

这就涉及到了**客户端重定向**机制。

#### 情况一：MOVED 错误 (永久重定向)

1. **客户端**：向 **节点 A** 发送 `GET user:100`。
2. **节点 A**：计算 `CRC16(user:100)`，发现属于 **槽位 5000**。
3. **节点 A**：查表发现槽位 5000 归 **节点 B** 管。
4. **节点 A**：返回一个 `MOVED 5000 192.168.1.2:6379` 的错误给客户端。
5. **客户端**：收到错误，**更新本地的槽位映射表**（以后再查 5000 槽，直接找 B），然后重新向 **节点 B** 发送请求。

#### 情况二：ASK 错误 (临时重定向)

这发生在**集群扩容（Resharding）**的时候。比如你正在把槽位 5000 从节点 A 迁移到节点 B。

1. **客户端**：向 **节点 A** 请求 `user:100`（属于槽位 5000）。
2. **节点 A**：发现槽位 5000 还在自己这，但 `user:100` 这个 Key 已经被迁移到 **节点 B** 了。
3. **节点 A**：返回 `ASK 5000 192.168.1.2:6379`。
4. **客户端**：收到 ASK，知道这是“临时的”。它向 **节点 B** 发送一个 `ASKING` 命令（打个招呼），然后再发送 `GET user:100`。
5. **区别**：客户端**不会**更新本地的槽位映射表。下次查槽位 5000，它还是会先问 A。

> Java 客户端 (Jedis/Lettuce) 的做法：
>
> 这一层逻辑被封装在 SDK 里了。你在代码里写 jedis.get("key") 时，底层如果收到了 MOVED，会自动重连新节点，你的业务代码是无感知的。

------

### 3. 核心通信：Gossip 协议

集群里的节点（比如 A, B, C）是怎么知道“谁挂了”、“哪个槽归谁管”的？

它们通过 Gossip（八卦）协议 互相传播信息。

每个节点都开了一个额外的端口（通常是 业务端口 + 10000，比如 16379），专门用来和其他节点“聊八卦”。

- **PING**：随机挑几个节点发消息：“我是 A，我负责 0-5000，我觉得 C 好像挂了，你们知道吗？”
- **PONG**：接收方回复：“我是 B，我知道了。另外我发现 D 也是好的。”

通过这种病毒式的传播，集群的状态最终会在几秒钟内达到一致。

------

### 4. 高可用与故障转移 (Failover)

Cluster 模式自带了 Sentinel 的功能。每个 Master 节点下面通常会挂 1 个或多个 Slave。

**如果 Master A 挂了：**

1. **PFAIL (疑似下线)**：节点 B 发现连不上 A 了，把 A 标记为 PFAIL。
2. **FAIL (确认下线)**：节点 B 把这个消息通过 Gossip 告诉其他节点。如果集群里**超过半数**的 Master 都认为 A 挂了，A 就会被标记为 FAIL。
3. **选举**：A 的 Slave 们会发起选举（基于 Raft 协议）。
4. **上位**：胜出的 Slave 升级为新的 Master，接管 A 原来的槽位。
5. **广播**：通过 Gossip 告诉大家：“槽位 0-5460 现在归我管了”。

------

### 5. 面试深挖：Cluster 的限制 (关键！)

用 Redis Cluster 不是没有代价的，这几点**非常限制业务开发**，也是面试常考点：

1. **只能使用 0 号数据库**：
   - 你之前问的“怎么选 15 号库”，在 Cluster 模式下**不生效**。Redis Cluster 只支持 db 0。这也是为了设计简单（跨库分片太复杂）。
2. **无法支持跨槽位的多 Key 操作**：
   - 命令：`MSET key1 value1 key2 value2`
   - **问题**：如果 `key1` 算出来在节点 A，`key2` 算出来在节点 B，这个操作会直接报错。Redis Cluster 不支持跨节点的事务。
   - **解决办法 (Hash Tag)**：
     - 如果你非要让这两个 Key 在同一个节点，可以使用 `{}` 强制指定 Hash 部分。
     - 比如：`user:{100}:profile` 和 `user:{100}:orders`。
     - Redis 只会计算 `{}` 中间的内容（即 `100`）的 CRC16。这样它俩一定在同一个槽，也就一定在同一个节点。

### 总结

Redis Cluster 的原理可以概括为：

1. **分片**：用 **16384 个哈希槽** 切分数据。
2. **路由**：客户端请求 -> 计算 CRC16 -> 找槽 -> 找节点（如果找错，节点返回 **MOVED** 重定向）。
3. **高可用**：节点间用 **Gossip** 协议互通有无，Master 挂了由内部 Slave 自动顶上。

这套机制让 Redis 真正具备了存 **TB 级别数据** 的能力。









# Spring



## 1. Spring事务

好的，Spring 事务管理是 Spring 框架中**最核心、最常用**的功能之一，也是保证企业级应用数据一致性的关键。下面我将系统地讲解 Spring 事务。



### 一、 什么是事务？



在谈论 Spring 事务之前，首先要理解什么是事务。事务是一个**不可分割的数据库操作序列**，它要么**全部成功**，要么**全部失败**。它必须遵循 **ACID** 原则：

- **A (Atomicity) 原子性**：事务中的所有操作是一个整体，要么全部完成，要么全部不完成。
- **C (Consistency) 一致性**：事务必须使数据库从一个一致性状态变换到另一个一致性状态。
- **I (Isolation) 隔离性**：多个并发事务之间相互隔离，一个事务的执行不应被其他事务干扰。
- **D (Durability) 持久性**：一个事务一旦被提交，它对数据库中数据的改变就是永久性的。



### 二、 Spring 事务的核心原理：AOP



Spring 并不直接实现事务，而是对底层数据库事务（如 JDBC 事务）或 JTA 事务进行了**统一的抽象和封装**。其核心实现是基于 **AOP (面向切面编程)**。

**工作流程如下**：

1. **代理创建**：当 Spring 容器启动时，如果发现一个 Bean 的某个 `public` 方法上标注了 `@Transactional` 注解，Spring AOP 会为这个 Bean 创建一个**代理对象 (Proxy)**。
2. **方法拦截**：当外部代码调用这个 Bean 的事务方法时，实际上调用的是这个代理对象的方法。
3. **事务开启**：代理对象在**执行真实方法之前**，会先开启一个事务（`BEGIN TRANSACTION`）。
4. **执行业务逻辑**：调用真实的 Bean 方法，执行具体的业务操作。
5. **事务提交/回滚**：
   - 如果真实方法**正常执行完毕**（没有抛出异常），代理对象会**提交事务**（`COMMIT`）。
   - 如果真实方法**抛出异常**，代理对象会**回滚事务**（`ROLLBACK`）。

这个过程对开发者是完全透明的，让我们能将业务代码和事务管理代码完全解耦。



### 三、 `@Transactional` 注解详解



`@Transactional` 是实现**声明式事务**最常用的方式，它有很多重要的属性来控制事务的行为。



#### 1. `propagation` (传播行为)



这是**最重要**的属性，它定义了当一个事务方法被另一个事务方法调用时，事务应该如何传播。

- **`REQUIRED` (默认值)**：如果当前存在事务，则加入该事务；如果当前没有事务，则创建一个新的事务。这是最常见的选择。
- **`REQUIRES_NEW`**：**总是创建一个新的事务**。如果当前存在事务，则将当前事务挂起。新事务与外部事务完全独立。
- **`SUPPORTS`**：如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务的方式继续运行。
- **`NOT_SUPPORTED`**：以非事务方式运行。如果当前存在事务，则将当前事务挂起。
- **`MANDATORY`**：必须在一个已有的事务中执行，否则抛出异常。
- **`NEVER`**：必须在一个非事务的环境中执行，否则抛出异常。
- **`NESTED`**：如果当前存在事务，则创建一个嵌套事务（基于数据库的 Savepoint 实现）。如果外部事务回滚，嵌套事务也会回滚。而嵌套事务的回滚不影响外部事务。



#### 2. `isolation` (隔离级别)



定义了事务的隔离级别，用来解决并发事务中的**脏读、不可重复读、幻读**等问题。

- **`DEFAULT` (默认值)**：使用底层数据库的默认隔离级别（如 MySQL InnoDB 默认为 `REPEATABLE_READ`）。
- **`READ_UNCOMMITTED`**：读未提交。
- **`READ_COMMITTED`**：读已提交（Oracle 默认）。
- **`REPEATABLE_READ`**：可重复读（MySQL InnoDB 默认）。
- **`SERIALIZABLE`**：串行化。



#### 3. 回滚规则 (`rollbackFor`, `noRollbackFor`)



这是一个非常关键且容易出错的地方。

- **默认行为**：Spring 的事务默认只在遇到 **`RuntimeException` (运行时异常)** 或 **`Error` (错误)** 时才会进行回滚。对于**受检异常 (Checked Exception)**，**默认是不回滚的**。

- **`rollbackFor`**：指定哪些异常类型需要触发事务回滚。

  Java

  ```
  @Transactional(rollbackFor = Exception.class) // 表示任何Exception都回滚
  public void myMethod() { ... }
  ```

- **`noRollbackFor`**：指定哪些异常类型**不**需要触发事务回滚。



#### 4. `readOnly` (只读)



- 将事务设置为只读模式。这可以作为一个性能优化的提示，告诉数据库这个事务不会进行写操作。



#### 5. `timeout` (超时)



- 指定事务的超时时间（秒）。如果事务在指定时间内未完成，将被强制回滚。



### 四、 事务失效的常见场景（非常重要！）



由于 Spring 事务是基于 AOP 代理实现的，在某些情况下，代理会失效，导致事务不生效。

1. 方法不是 public：

   @Transactional 必须用在 public 方法上才能生效。因为代理模式无法拦截 protected, private 或 package-private 方法的调用。

2. 方法内部调用 (Self-Invocation)：

   最常见的失效原因。在一个类的非事务方法中，通过 this 关键字调用本类中的事务方法，事务不会生效。

   - **原因**：`this` 指向的是原始对象，而不是 Spring 创建的代理对象。调用 `this.b()` 会绕过代理，直接执行原始对象的代码，AOP 拦截自然就失效了。
   - **解决**：将事务方法移到另一个 Bean 中，通过依赖注入调用；或者注入自己代理对象再调用。

3. 异常被 catch 捕获：

   如果在事务方法内部使用了 try-catch 块捕获了异常，并且没有在 catch 块中将异常重新抛出，那么 Spring 的事务切面就无法感知到异常的发生，也就不会触发回滚。

4. 回滚规则配置错误：

   方法抛出了一个受检异常（如 IOException），但没有通过 rollbackFor 属性指定该异常需要回滚，事务也不会回滚。

5. 数据库引擎不支持事务：

   如果你的 MySQL 表使用的是 MyISAM 存储引擎，那么无论 Spring 如何配置，事务都不会生效，因为 MyISAM 本身就不支持事务。



## 2. 事务传播行为

当然可以。Spring 事务的传播行为（Transaction Propagation）是 `@Transactional` 注解中**最重要、也最能体现其灵活性的属性**。



### 什么是事务传播行为？



**一句话解释**：事务传播行为定义了当一个带有事务的方法（我们称之为**外部方法**）调用另一个也带有事务的方法（**内部方法**）时，内部方法的事务应该如何运行。例如，内部方法是应该加入外部方法的现有事务，还是应该开启一个全新的事务？

理解这一点对于设计复杂的、多服务调用的业务逻辑至关重要。

Spring 定义了七种传播行为，我们可以将它们分为三类来理解。

------



### 第一类：支持当前事务（最常用）



这类传播行为会尝试加入一个已经存在的事务。



#### 1. `PROPAGATION_REQUIRED` (默认值)



- **一句话解释**：**如果存在事务，则加入；如果不存在，则创建新的。**
- **详细说明**：
  - **外部方法有事务**：当外部方法 `A()` 调用内部方法 `B()` 时，`B()` 会**加入** `A()` 的事务，成为这个事务的一部分。它们共享同一个数据库连接，要么一起成功提交，要么一起失败回滚。
  - **外部方法无事务**：当 `A()` 没有事务时，`B()` 会为自己**创建一个新的事务**，独立地运行。
- **使用场景**：这是**最常用**的传播行为，适用于绝大多数业务场景，如增、删、改操作。它能确保一个完整的业务流程（可能跨越多个方法）被包裹在同一个事务中。



#### 2. `PROPAGATION_SUPPORTS`



- **一句话解释**：**如果存在事务，则加入；如果不存在，则以非事务方式运行。**
- **详细说明**：
  - **外部方法有事务**：`B()` 加入 `A()` 的事务。
  - **外部方法无事务**：`B()` **不会**创建新事务，它的所有数据库操作都会在非事务性的状态下执行（通常意味着自动提交）。
- **使用场景**：通常用于一些**只读**或非核心的业务方法。这些方法可以参与到一个事务中，但本身并不强制要求事务存在。



#### 3. `PROPAGATION_MANDATORY`



- **一句话解释**：**强制要求必须存在一个事务，否则抛出异常。**
- **详细说明**：
  - **外部方法有事务**：`B()` 加入 `A()` 的事务。
  - **外部方法无事务**：直接抛出异常 `IllegalTransactionStateException`。
- **使用场景**：不常用。通常用于一些核心的、必须在事务上下文中执行的工具类或内部方法，以确保它们不会被错误地在非事务状态下调用。

------



### 第二类：不支持当前事务



这类传播行为会避免在一个已存在的事务中运行。



#### 4. `PROPAGATION_REQUIRES_NEW`



- **一句话解释**：**总是创建一个全新的、独立的事务。**
- **详细说明**：
  - **外部方法有事务**：当 `A()` 调用 `B()` 时，`A()` 的事务会被**挂起（pause）**。`B()` 会开启一个**全新的、完全独立**的事务。`B()` 的事务提交或回滚，**完全不影响** `A()` 的事务。`B()` 执行完毕后，`A()` 的事务才会**恢复（resume）**。
  - **外部方法无事务**：`B()` 同样会为自己创建一个新的事务。
- **使用场景**：**非常重要**。当你希望内部方法的事务独立于外部方法，确保其操作**无论外部事务成功与否都能独立提交**时使用。
  - **经典案例**：在一个订单处理方法 `placeOrder()`（有事务）中，需要调用一个日志记录方法 `logOperation()`（也有事务）。我们希望**无论订单处理成功还是失败回滚，这条操作日志都必须成功保存到数据库**。此时就应将 `logOperation()` 的传播行为设置为 `REQUIRES_NEW`。



#### 5. `PROPAGATION_NOT_SUPPORTED`



- **一句话解释**：**以非事务方式运行，如果存在事务，则将其挂起。**
- **详细说明**：
  - **外部方法有事务**：`A()` 的事务会被挂起，`B()` 的所有数据库操作都在非事务状态下执行。
  - **外部方法无事务**：`B()` 同样在非事务状态下执行。
- **使用场景**：当你确定某个方法的数据库操作不需要事务支持，且不希望它受外部事务影响时使用。



#### 6. `PROPAGATION_NEVER`



- **一句话解释**：**强制要求必须在非事务状态下运行，否则抛出异常。**
- **详细说明**：
  - **外部方法有事务**：直接抛出异常。
  - **外部方法无事务**：正常在非事务状态下执行。
- **使用场景**：与 `MANDATORY` 相对，用于确保某个方法绝对不会被事务包裹。

------



### 第三类：嵌套事务





#### 7. `PROPAGATION_NESTED`



- **一句话解释**：**在现有事务中创建一个嵌套的子事务。**
- **详细说明**：
  - **外部方法有事务**：`B()` 会创建一个基于数据库**保存点 (Savepoint)** 的**嵌套事务**。`B()` 可以独立地回滚（回滚到保存点），而不影响 `A()`。但是，如果 `A()` 发生回滚，那么 `B()` 的所有操作也**必定会回滚**。
  - **外部方法无事务**：`B()` 的行为同 `REQUIRED`，即创建一个新事务。
- **与 `REQUIRES_NEW` 的核心区别**：
  - `REQUIRES_NEW` 创建的是一个**完全独立的物理事务**。
  - `NESTED` 创建的是一个**依赖于外部事务的子事务**。外部事务的回滚会影响它，但它的回滚不一定会影响外部事务。
- **使用场景**：用于复杂的业务场景，你希望一个子流程可以独立回滚，但又不希望它脱离主流程的整体控制。**注意**：不是所有数据库都支持保存点。



### 总结表格



| **传播行为**       | **外部有事务**               | **外部无事务**   | **核心场景**                 |
| ------------------ | ---------------------------- | ---------------- | ---------------------------- |
| **`REQUIRED`**     | **加入当前事务**             | **创建新事务**   | **绝大多数业务方法（默认）** |
| **`REQUIRES_NEW`** | **挂起当前事务，创建新事务** | 创建新事务       | **日志记录、独立业务单元**   |
| `SUPPORTS`         | 加入当前事务                 | 以非事务方式运行 | 非核心的只读方法             |
| `MANDATORY`        | 加入当前事务                 | 抛出异常         | 必须在事务中调用的工具方法   |
| `NOT_SUPPORTED`    | 挂起当前事务                 | 以非事务方式运行 | 确定不需要事务的方法         |
| `NEVER`            | 抛出异常                     | 以非事务方式运行 | 确定不能在事务中调用的方法   |
| `NESTED`           | **创建嵌套事务 (Savepoint)** | 创建新事务       | 可独立回滚的复杂子流程       |



## 3. Bean的生命周期

我们可以将 Bean 的生命周期精炼为四个主要阶段：**BeanDefinition 阶段**、**实例化阶段**、**初始化阶段**和**存储阶段**。

------

### 第一阶段：BeanDefinition 阶段（准备蓝图）

在对象被创建之前，Spring 必须先弄清楚“要创建一个什么样的对象”。

- **读取与封装**：Spring 扫描你的配置（注解或 XML），将类的信息（类名、作用域、是否懒加载等）封装成 `BeanDefinition` (BD) 对象。
- **存入 Map**：这些 BD 对象会被注册到 `beanDefinitionMap` 中，供后续生产使用。
- **后置处理（扩展点）**：
  - 执行 `BeanDefinitionRegistryPostProcessor`：允许在运行时动态注册更多的 Bean。
  - 执行 `BeanFactoryPostProcessor`：允许修改已注册的 BD 信息（例如解析占位符 `${...}`）。

### 第二阶段：Bean 实例化阶段（创建“半成品”）

这一步是真正开始在堆内存中分配空间。

- **从 BD 到 Obj**：Spring 根据 `beanDefinitionMap` 中的信息，通过反射调用构造函数创建 Bean 实例。
- **半成品状态**：此时的对象被称为“半成品”，因为它仅仅被实例化了，但**还没有进行属性填充**，也没有执行任何生命周期相关的逻辑。

### 第三阶段：Bean 初始化阶段（加工与增强）

这是最核心、面试考点最多的部分，它决定了一个普通 Java 对象如何变成一个功能强大的 Spring Bean。

1. **属性填充 (populate)**：Spring 将依赖的对象或值注入到 Bean 的成员变量中（如 `@Autowired` 的处理）。
2. **Aware 接口回调**：Spring 调用各种 Aware 接口方法，给 Bean 注入容器资源（如 `BeanName`、`BeanFactory` 等）。
3. **BeanPostProcessor #before()**：执行后置处理器的前置方法。
4. **初始化方法**：
   - 执行 `InitializingBean` 接口的 `afterPropertiesSet`。
   - 执行在配置中定义的 `init` 方法。
5. **BeanPostProcessor #after()（关键）**：执行后置处理器的后置方法。**Spring 的大多数功能增强，尤其是 AOP（动态代理）和注解解析，都是在这一步完成的**。如果需要 AOP，这里返回的将是代理对象而非原始对象。

### 第四阶段：Bean 存储阶段（成品入库）

- **单例池存储**：经过初始化后的“成品”对象会被放入名为 `singletonObjects` 的 Map 中（即常说的**单例池**或**一级缓存**）。
- **就绪待用**：至此，Bean 已经完全准备好，当你通过 `getBean()` 或依赖注入使用它时，Spring 直接从这个单例池中获取。

------

### 总结

- **实例化 vs 初始化**：实例化是 **`new` 对象**，分配内存；初始化是 **赋值、增强、回调**，让对象可用。
- **AOP 发生在什么时候？** 发生在初始化阶段的 `BeanPostProcessor#after()` 之后。如果没有这一步，你拿到的就是一个普通的类实例，而不是具有事务或日志功能的代理对象。
- **为什么需要 BeanFactoryPostProcessor？** 因为它能让你在对象创建之前修改“蓝图”（BD），比如把 `${db.url}` 替换成真正的数据库连接字符串。







# SpringCloud





## 1. HTTP调用与OpenFeign调用：深入解析两者差异

在现代软件开发，尤其是在微服务架构中，服务间的通信至关重要。HTTP作为互联网数据通信的基石，是实现这种通信的主要协议。然而，直接使用HTTP进行编程较为繁琐，因此涌现了许多简化操作的框架，OpenFeign便是其中之一。本文将深入探讨HTTP调用与OpenFeign调用的核心区别。



### 核心概念：协议与客户端库



首先，需要明确两者的根本不同：

- **HTTP (HyperText Transfer Protocol, 超文本传输协议)** 是一种**应用层协议**。它定义了客户端和服务器之间交换数据的格式和规则，是万维网数据通信的基础。它本身并不是一种具体的实现或代码库，而是一套标准。
- **OpenFeign** 是一个**声明式的HTTP客户端库**。它构建在HTTP协议之上，为Java开发者提供了一种更优雅、更简洁的方式来发起HTTP请求。你可以将它理解为对原生HTTP调用的一种高级封装，它使得调用远程HTTP服务就像调用本地方法一样简单。



### 主要区别详解



| **特性**               | **直接HTTP调用 (例如使用 RestTemplate 或 HttpClient)**       | **OpenFeign 调用**                                           |
| ---------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **编程模型**           | **命令式 (Imperative)**                                      | **声明式 (Declarative)**                                     |
|                        | 开发者需要手动编写代码来构建HTTP请求的各个部分，包括URL、请求头、请求体、参数等，然后执行请求并解析响应。代码通常较为冗长。 | 开发者只需定义一个接口，并使用注解来描述HTTP请求的细节（如URL、请求方法、请求头等）。框架会自动在运行时生成实现类来处理实际的HTTP通信。 |
| **代码简洁度**         | **较低**                                                     | **非常高**                                                   |
|                        | 需要编写大量样板代码（boilerplate code）来处理请求的构建、执行、错误处理和响应解析。 | 极大地减少了代码量，使得代码更易读、更易于维护。开发者可以更专注于业务逻辑而非HTTP通信的底层细节。 |
| **服务发现与负载均衡** | **需手动集成**                                               | **自动集成**                                                 |
|                        | 在微服务环境中，需要手动与服务发现组件（如Eureka, Consul）集成，以获取服务实例的地址和端口，并自行实现或集成客户端负载均衡策略（如Ribbon）。 | 与Spring Cloud生态系统无缝集成。可以自动从服务注册中心发现服务，并通过内置的负载均衡器（如Spring Cloud LoadBalancer）将请求分发到健康的服务实例上。开发者只需使用服务名即可调用，无需关心具体的IP地址和端口。 |
| **可读性与维护性**     | **较差**                                                     | **优秀**                                                     |
|                        | 请求的URL和参数散落在代码各处，难以集中管理和维护。          | 所有的API定义都集中在接口中，一目了然，非常清晰。接口本身就是一份动态的API文档。 |
| **灵活性与控制力**     | **高**                                                       | **相对较低**                                                 |
|                        | 开发者可以完全控制HTTP请求的每一个细节，适用于需要进行精细化定制和优化的复杂场景。 | 虽然提供了丰富的配置选项（如超时、重试、拦截器等），但在某些极端情况下，对底层HTTP请求的控制力不如直接调用。 |
| **错误处理**           | **需手动实现**                                               | **提供内置机制**                                             |
|                        | 需要编写`try-catch`块来处理各种网络异常和HTTP错误状态码。    | 提供了错误解码器（ErrorDecoder），可以将HTTP错误响应转化为自定义的异常，并能与断路器（如Resilience4j）结合，实现服务降级和熔断策略。 |



### 场景选择：何时使用哪种方式？



- **选择直接HTTP调用：**
  - 当你需要对HTTP请求进行极度精细的控制，例如自定义复杂的认证逻辑、处理特殊的响应格式或进行底层性能调优。
  - 在非Spring Cloud环境中，或者项目中仅需要进行少数简单的HTTP调用，引入OpenFeign可能显得过于“重”。
  - 与一些不支持标准RESTful风格的旧系统进行交互。
- **选择OpenFeign调用：**
  - 在**微服务架构**中，特别是使用**Spring Cloud**生态系统的项目，OpenFeign是进行服务间通信的首选。
  - 当项目中有大量的服务间调用时，OpenFeign可以极大地提升开发效率，降低代码复杂度和维护成本。
  - 当你希望代码更加清晰、可读，并能从服务发现和负载均衡等集成特性中受益时。



### 总结



总而言之，HTTP是一种通信协议，而OpenFeign是一个基于该协议的、用于简化开发的客户端工具。直接进行HTTP调用给予了开发者最大的灵活性和控制力，但代价是代码的复杂性和开发效率的降低。OpenFeign通过其声明式、面向接口的编程模型，将开发者从繁琐的HTTP通信细节中解放出来，尤其是在微服务架构下，其与服务治理体系的无缝集成使其成为一个强大而高效的选择。











# 系统设计



## 1. 为第三方提供API的考虑方向

好的，这是一个非常有价值的实践问题，它考察的是从一个内部功能模块，向一个对外、可靠、安全的生产级服务演进时需要具备的系统设计能力。

根据你实习中“统计列车开行情况”的工作，要向携程、飞猪这样的第三方公司提供API，你需要从**设计原则**和**具体实现方案**两个层面来考虑。

------



### **第一部分：需要考虑的方面 (设计原则)**



在编写任何代码之前，必须先思考以下几个关键方面，它们决定了你的API是否专业和可靠。

1. **安全性 (Security)**
   - **认证 (Authentication)**：我如何知道是谁在调用我？必须确保只有授权的第三方（如携程）才能访问。绝不能允许匿名访问。
   - **授权 (Authorization)**：携程调用我的API，它有哪些权限？能访问所有数据，还是只能访问部分数据？
   - **传输安全**：API必须使用 HTTPS (TLS加密) 来防止数据在传输过程中被窃听或篡改。
   - **防攻击**：需要考虑如何防止常见的Web攻击，如SQL注入、重放攻击等。
2. **性能与稳定性 (Performance & Stability)**
   - **高吞吐量**：携程、飞猪的请求量可能是巨大的。你的API必须能够处理高并发请求。
   - **低延迟**：查询列车状态这类信息，要求响应速度快。
   - **限流 (Rate Limiting)**：必须对第三方进行速率限制，防止某个调用方因为程序bug或恶意攻击，发送海量请求拖垮你的整个系统。
   - **熔断与降级**：如果你的API依赖的其他内部服务（比如数据库）出现问题，API本身不能崩溃，应该能快速失败（熔断）或返回一个兜底数据（降级）。
3. **可靠性与可用性 (Reliability & Availability)**
   - **高可用**：API服务需要集群化部署，避免单点故障。一个服务器实例宕机，不应影响整体服务。
   - **监控与告警**：需要对API的健康状况（如响应时间、错误率、请求量）进行实时监控，并在出现问题时立即告警。
4. **可维护性与易用性 (Maintainability & Usability)**
   - **清晰的文档**：必须提供非常清晰、详尽的API文档，包含每个接口的URL、参数说明、返回值示例和错误码解释。
   - **版本控制 (Versioning)**：API一旦发布，就不能随意修改。如果未来需要进行不兼容的改动，应该发布一个新的版本（如 `/v2/`），同时维护旧版本。
   - **统一的错误处理**：提供标准、一致的错误响应格式，方便调用方进行程序化处理。

------



### **第二部分：具体的实现方案**



基于以上原则，我们可以设计一套现代、标准的微服务架构方案，其中**API网关**是整个方案的核心。



#### **1. 整体架构：API网关模式**



我们不会让第三方直接调用我们的业务服务。而是在业务服务前面加一个“哨兵”——API网关。

**调用流程**：`携程/飞猪 -> API网关 -> 内部的列车信息服务`

**技术选型**：可以使用 **Spring Cloud Gateway** 或 Kong。



#### **2. 具体实现细节**



1. **认证方案：API Key + 签名 (Signature)**

   - **颁发凭证**：为每个第三方（如携程）分配一个唯一的 `appKey` 和一个更长的 `appSecret`（密钥，仅客户端和服务器知道）。
   - **调用过程**：
     1. 携程在发起请求时，将所有请求参数（包括`appKey`、时间戳`timestamp`、随机数`nonce`）按字母顺序排序。
     2. 将排序后的参数拼接成一个字符串。
     3. 使用`appSecret`对这个字符串进行 HMAC-SHA256 等算法加密，生成一个**签名 (signature)**。
     4. 将`appKey`, `timestamp`, `nonce`, 和 `signature` 全部放在请求头 (Request Header) 中发送过来。
   - **验证过程**：你的 **API网关** 收到请求后，用同样的方式在服务器端生成一遍签名，与携程传过来的签名进行比对。如果一致，则认证通过；不一致则拒绝。
   - **优点**：可以有效防止请求被篡改和重放攻击。

2. **限流方案：令牌桶算法**

   - 在 **API网关** 层，集成**Redis**来实现限流。
   - **实现**：Spring Cloud Gateway 提供了基于 Redis 的 `RequestRateLimiter`，可以非常方便地配置。我们可以为不同的 `appKey` 设置不同的速率，比如允许携程每秒1000次请求，而其他小程序每秒100次。

3. **API 设计：RESTful 风格与版本控制**

   - **URL设计**：采用清晰的 RESTful 风格，并将版本号放入URL中。

     - 查询特定车次状态: `GET /v1/trains/status?trainNumber=G250`
     - 查询某站点的出发车次: `GET /v1/stations/beijing/departures?date=2025-10-16`

   - **响应格式**：设计统一的JSON响应体。

     JSON

     ```
     {
       "code": 0, // 0表示成功，其他表示错误
       "message": "Success",
       "data": { // 业务数据
         "trainNumber": "G250",
         "status": "On Time",
         "currentLocation": "Jinan West"
       }
     }
     ```

   - **分页**：对于返回列表的接口，使用 `page` 和 `pageSize` 参数进行分页。

4. **缓存策略**

   - 对于不经常变化的数据（如某车次一天的固定时刻表），可以在业务服务中加入 **Redis 缓存**，极大地减轻数据库压力。
   - 对于实时性要求高的数据（如“晚点5分钟”），可以设置一个非常短的缓存时间（如10-30秒），或者不缓存。

5. **文档方案：Swagger / OpenAPI**

   - 在你的 Spring Boot 业务服务中，集成 Swagger (OpenAPI 3) 依赖。
   - 通过在 Controller 的接口上添加注解，可以自动生成一个交互式的API文档网站。将这个网站地址提供给第三方即可。

通过这一整套“**API网关 + 签名认证 + Redis限流缓存 + Swagger文档**”的方案，你就可以构建出一个安全、高性能且专业的对外API服务了。  



























